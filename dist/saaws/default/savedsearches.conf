#############
# Automatically generated by generator.py in splunk/security_content
# On Date: 2021-03-30T19:36:01 UTC
# Author: Splunk Security Research
# Contact: research@splunk.com
#############

### ESCU DETECTIONS ###

[ESCU - AWS Create Policy Version to allow all resources - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user created a policy version that allows them to access any resource in their account
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user created a policy version that allows them to access any resource in their account
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a policy to allow a user to access all resources. That said, AWS strongly advises against granting full control to all AWS resources
action.escu.creation_date = 2021-02-22
action.escu.modification_date = 2021-02-22
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Create Policy Version to allow all resources - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS IAM Privilege Escalation"]
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Create Policy Version to allow all resources - Rule
action.correlationsearch.annotations = {"analytic_story": ["AWS IAM Privilege Escalation"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=CreatePolicyVersion eventSource = iam.amazonaws.com errorCode = success | spath input=requestParameters.policyDocument output=key_policy_statements path=Statement{} | mvexpand key_policy_statements | spath input=key_policy_statements output=key_policy_action_1 path=Action | search key_policy_action_1 = "*" | stats count min(_time) as firstTime max(_time) as lastTime values(key_policy_statements) as policy_added by eventName eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.principalId user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`aws_create_policy_version_to_allow_all_resources_filter`

[ESCU - AWS CreateAccessKey - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user A who has already permission to create access keys, makes an API call to create access keys for another user B. Attackers have been know to use this technique for Privilege Escalation in case new victim(user B) has more permissions than old victim(user B)
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user A who has already permission to create access keys, makes an API call to create access keys for another user B. Attackers have been know to use this technique for Privilege Escalation in case new victim(user B) has more permissions than old victim(user B)
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created keys for another user.
action.escu.creation_date = 2021-03-02
action.escu.modification_date = 2021-03-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS CreateAccessKey - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS IAM Privilege Escalation"]
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS CreateAccessKey - Rule
action.correlationsearch.annotations = {"analytic_story": ["AWS IAM Privilege Escalation"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName = CreateAccessKey userAgent !=console.amazonaws.com errorCode = success| search userName!=requestParameters.userName  |  stats count min(_time) as firstTime max(_time) as lastTime  by requestParameters.userName src eventName eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.principalId user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`aws_createaccesskey_filter`

[ESCU - AWS CreateLoginProfile - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user A(victim A) creates a login profile for user B, followed by a AWS Console login event from user B from the same src_ip as user B. This correlated event can be indicative of privilege escalation since both events happened from the same src_ip
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user A(victim A) creates a login profile for user B, followed by a AWS Console login event from user B from the same src_ip as user B. This correlated event can be indicative of privilege escalation since both events happened from the same src_ip
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a login profile for another user.
action.escu.creation_date = 2021-03-02
action.escu.modification_date = 2021-03-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS CreateLoginProfile - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS IAM Privilege Escalation"]
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS CreateLoginProfile - Rule
action.correlationsearch.annotations = {"analytic_story": ["AWS IAM Privilege Escalation"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName = CreateLoginProfile | rename requestParameters.userName as new_login_profile | table src_ip eventName new_login_profile userName | join new_login_profile src_ip [| search `cloudtrail` eventName = ConsoleLogin | rename userName as new_login_profile | stats count values(eventName) min(_time) as firstTime max(_time) as lastTime by eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.principalId user_arn new_login_profile src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`] | `aws_createloginprofile_filter`

[ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.  This search is deprecated and have been translated to use the latest Authentication Datamodel.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.  This search is deprecated and have been translated to use the latest Authentication Datamodel.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen AWS Cross Account Activity - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen AWS Cross Account Activity - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `aws_cross_account_activity_from_previously_unseen_account_filter` macro.
action.escu.known_false_positives = Using multiple AWS accounts and roles is perfectly valid behavior. It's suspicious when an account requests privileges of an account it hasn't before. You should validate with the account owner that this is a legitimate request.
action.escu.creation_date = 2020-05-28
action.escu.modification_date = 2020-05-28
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 15
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud Authentication Activities"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats min(_time) as firstTime max(_time) as lastTime from datamodel=Authentication where Authentication.signature=AssumeRole by Authentication.vendor_account Authentication.user Authentication.src Authentication.user_role | `drop_dm_object_name(Authentication)` | rex field=user_role "arn:aws:sts:*:(?<dest_account>.*):" | where vendor_account != dest_account | rename vendor_account as requestingAccountId dest_account as requestedAccountId | lookup previously_seen_aws_cross_account_activity requestingAccountId, requestedAccountId, OUTPUTNEW firstTime | eval status = if(firstTime > relative_time(now(), "-24h@h"),"New Cross Account Activity","Previously Seen") |  where status = "New Cross Account Activity" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `aws_cross_account_activity_from_previously_unseen_account_filter`

[ESCU - AWS Detect Users creating keys with encrypt policy without MFA - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection of KMS keys which action kms:Encrypt is accessible for everyone (also outside of your organization). This is an identicator that your account is compromised and the attacker uses the encryption key to compromise another company.
action.escu.mappings = {"mitre_attack": ["T1486"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection of KMS keys which action kms:Encrypt is accessible for everyone (also outside of your organization). This is an identicator that your account is compromised and the attacker uses the encryption key to compromise another company.
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs
action.escu.known_false_positives = unknown
action.escu.creation_date = 2021-01-11
action.escu.modification_date = 2021-01-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Detect Users creating keys with encrypt policy without MFA - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Ransomware Cloud"]
action.risk = 1
action.risk.param._risk_object = userIdentity.principalId
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Detect Users creating keys with encrypt policy without MFA - Rule
action.correlationsearch.annotations = {"analytic_story": ["Ransomware Cloud"], "mitre_attack": ["T1486"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=CreateKey OR eventName=PutKeyPolicy | spath input=requestParameters.policy output=key_policy_statements path=Statement{} | mvexpand key_policy_statements | spath input=key_policy_statements output=key_policy_action_1 path=Action | spath input=key_policy_statements output=key_policy_action_2 path=Action{} | eval key_policy_action=mvappend(key_policy_action_1, key_policy_action_2) | spath input=key_policy_statements output=key_policy_principal path=Principal.AWS | search key_policy_action="kms:Encrypt" AND key_policy_principal="*" | stats count min(_time) as firstTime max(_time) as lastTime by eventName eventSource eventID awsRegion userIdentity.principalId | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`aws_detect_users_creating_keys_with_encrypt_policy_without_mfa_filter`

[ESCU - AWS Detect Users with KMS keys performing encryption S3 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection of users with KMS keys performing encryption specifically against S3 buckets.
action.escu.mappings = {"mitre_attack": ["T1486"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection of users with KMS keys performing encryption specifically against S3 buckets.
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs
action.escu.known_false_positives = bucket with S3 encryption
action.escu.creation_date = 2021-01-11
action.escu.modification_date = 2021-01-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Detect Users with KMS keys performing encryption S3 - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Ransomware Cloud"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 25
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Detect Users with KMS keys performing encryption S3 - Rule
action.correlationsearch.annotations = {"analytic_story": ["Ransomware Cloud"], "mitre_attack": ["T1486"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=CopyObject requestParameters.x-amz-server-side-encryption="aws:kms" | rename requestParameters.bucketName AS bucket_name, requestParameters.x-amz-copy-source AS src_file, requestParameters.key AS dest_file | stats count min(_time) as firstTime max(_time) as lastTime values(src_file) AS src_file values(dest_file) AS dest_file values(userAgent) AS userAgent values(region) AS region values(src) AS src by user | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`aws_detect_users_with_kms_keys_performing_encryption_s3_filter`

[ESCU - AWS Network Access Control List Created with All Open Ports - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1562.007"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS, version 4.4.0 or later, and configure your CloudTrail inputs.
action.escu.known_false_positives = It's possible that an admin has created this ACL with all ports open for some legitimate purpose however, this should be scoped and not allowed in production environment.
action.escu.creation_date = 2021-01-11
action.escu.modification_date = 2021-01-11
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Network Access Control List Created with All Open Ports - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Network ACL Activity"]
action.risk = 1
action.risk.param._risk_object = userName
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Network Access Control List Created with All Open Ports - Rule
action.correlationsearch.annotations = {"analytic_story": ["AWS Network ACL Activity"], "cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1562.007"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=CreateNetworkAclEntry OR eventName=ReplaceNetworkAclEntry requestParameters.ruleAction=allow requestParameters.egress=false requestParameters.aclProtocol=-1 | append [search `cloudtrail` eventName=CreateNetworkAclEntry OR eventName=ReplaceNetworkAclEntry requestParameters.ruleAction=allow requestParameters.egress=false requestParameters.aclProtocol!=-1 | eval port_range='requestParameters.portRange.to' - 'requestParameters.portRange.from' | where port_range>1024] | fillnull | stats count min(_time) as firstTime max(_time) as lastTime by userName userIdentity.principalId eventName requestParameters.ruleAction requestParameters.egress requestParameters.aclProtocol requestParameters.portRange.to requestParameters.portRange.from src userAgent requestParameters.cidrBlock | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `aws_network_access_control_list_created_with_all_open_ports_filter`

[ESCU - AWS Network Access Control List Deleted - Rule]
action.escu = 0
action.escu.enabled = 1
description = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
action.escu.mappings = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1562.007"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = It's possible that a user has legitimately deleted a network ACL.
action.escu.creation_date = 2021-01-12
action.escu.modification_date = 2021-01-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS Network Access Control List Deleted - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Network ACL Activity"]
action.risk = 1
action.risk.param._risk_object = userName
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 5
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS Network Access Control List Deleted - Rule
action.correlationsearch.annotations = {"analytic_story": ["AWS Network ACL Activity"], "cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1562.007"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=DeleteNetworkAclEntry requestParameters.egress=false | fillnull | stats count min(_time) as firstTime max(_time) as lastTime by userName userIdentity.principalId eventName requestParameters.egress src userAgent | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `aws_network_access_control_list_deleted_filter`

[ESCU - AWS SAML Access by Provider User and Principal - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides specific SAML access from specific Service Provider, user and targeted principal at AWS. This search provides specific information to detect abnormal access or potential credential hijack or forgery, specially in federated environments using SAML protocol inside the perimeter or cloud provider.
action.escu.mappings = {"mitre_attack": ["T1078"]}
action.escu.data_models = []
action.escu.eli5 = This search provides specific SAML access from specific Service Provider, user and targeted principal at AWS. This search provides specific information to detect abnormal access or potential credential hijack or forgery, specially in federated environments using SAML protocol inside the perimeter or cloud provider.
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs
action.escu.known_false_positives = Attacks using a Golden SAML or SAML assertion hijacks or forgeries are very difficult to detect as accessing cloud providers with these assertions looks exactly like normal access, however things such as source IP sourceIPAddress user, and principal targeted at receiving cloud provider along with endpoint credential access and abuse detection searches can provide the necessary context to detect these attacks.
action.escu.creation_date = 2021-01-26
action.escu.modification_date = 2021-01-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS SAML Access by Provider User and Principal - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Federated Credential Abuse"]
action.risk = 1
action.risk.param._risk_object = recipientAccountId
action.risk.param._risk_object_type = other
action.risk.param._risk_score = 25
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS SAML Access by Provider User and Principal - Rule
action.correlationsearch.annotations = {"analytic_story": ["Cloud Federated Credential Abuse"], "mitre_attack": ["T1078"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=Assumerolewithsaml | stats count min(_time) as firstTime max(_time) as lastTime by requestParameters.principalArn requestParameters.roleArn requestParameters.roleSessionName recipientAccountId responseElements.issuer sourceIPAddress userAgent | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`aws_saml_access_by_provider_user_and_principal_filter`

[ESCU - AWS SAML Update identity provider - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search provides detection of updates to SAML provider in AWS. Updates to SAML provider need to be monitored closely as they may indicate possible perimeter compromise of federated credentials, or backdoor access from another cloud provider set by attacker.
action.escu.mappings = {"mitre_attack": ["T1078"]}
action.escu.data_models = []
action.escu.eli5 = This search provides detection of updates to SAML provider in AWS. Updates to SAML provider need to be monitored closely as they may indicate possible perimeter compromise of federated credentials, or backdoor access from another cloud provider set by attacker.
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
action.escu.known_false_positives = Updating a SAML provider or creating a new one may not necessarily be malicious however it needs to be closely monitored.
action.escu.creation_date = 2021-01-26
action.escu.modification_date = 2021-01-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS SAML Update identity provider - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Federated Credential Abuse"]
action.risk = 1
action.risk.param._risk_object = sourceIPAddress
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS SAML Update identity provider - Rule
action.correlationsearch.annotations = {"analytic_story": ["Cloud Federated Credential Abuse"], "mitre_attack": ["T1078"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=UpdateSAMLProvider | stats count min(_time) as firstTime max(_time) as lastTime by eventType eventName requestParameters.sAMLProviderArn userIdentity.sessionContext.sessionIssuer.arn sourceIPAddress userIdentity.accessKeyId userIdentity.principalId | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`aws_saml_update_identity_provider_filter`

[ESCU - AWS SetDefaultPolicyVersion - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user has set a default policy versions. Attackers have been know to use this technique for Privilege Escalation in case the previous versions of the policy had permissions to access more resources than the current version of the policy
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user has set a default policy versions. Attackers have been know to use this technique for Privilege Escalation in case the previous versions of the policy had permissions to access more resources than the current version of the policy
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately set a default policy to allow a user to access all resources. That said, AWS strongly advises against granting full control to all AWS resources
action.escu.creation_date = 2021-03-02
action.escu.modification_date = 2021-03-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS SetDefaultPolicyVersion - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS IAM Privilege Escalation"]
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS SetDefaultPolicyVersion - Rule
action.correlationsearch.annotations = {"analytic_story": ["AWS IAM Privilege Escalation"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName=SetDefaultPolicyVersion eventSource = iam.amazonaws.com | stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.policyArn) as policy_arn by src requestParameters.versionId eventName eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.principalId user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_setdefaultpolicyversion_filter`

[ESCU - AWS UpdateLoginProfile - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user A who has already permission to update login profile, makes an API call to update login profile for another user B . Attackers have been know to use this technique for Privilege Escalation in case new victim(user B) has more permissions than old victim(user B)
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user A who has already permission to update login profile, makes an API call to update login profile for another user B . Attackers have been know to use this technique for Privilege Escalation in case new victim(user B) has more permissions than old victim(user B)
action.escu.how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created keys for another user.
action.escu.creation_date = 2021-03-02
action.escu.modification_date = 2021-03-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - AWS UpdateLoginProfile - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS IAM Privilege Escalation"]
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - AWS UpdateLoginProfile - Rule
action.correlationsearch.annotations = {"analytic_story": ["AWS IAM Privilege Escalation"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventName = UpdateLoginProfile userAgent !=console.amazonaws.com errorCode = success| search userName!=requestParameters.userName  |  stats count min(_time) as firstTime max(_time) as lastTime  by requestParameters.userName src eventName eventSource aws_account_id errorCode userAgent eventID awsRegion userName user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`aws_updateloginprofile_filter`

[ESCU - Abnormally High Number Of Cloud Infrastructure API Calls - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect a spike in the number of API calls made to your cloud infrastructure environment by a user.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search will detect a spike in the number of API calls made to your cloud infrastructure environment by a user.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Infrastructure API Calls Per User` to create the probability density function.
action.escu.known_false_positives = 
action.escu.creation_date = 2020-09-07
action.escu.modification_date = 2020-09-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Abnormally High Number Of Cloud Infrastructure API Calls - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud User Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 25
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Abnormally High Number Of Cloud Infrastructure API Calls - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud User Activities"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats count as api_calls values(All_Changes.command) as command from datamodel=Change where All_Changes.user!=unknown All_Changes.status=success by All_Changes.user _time span=1h | `drop_dm_object_name("All_Changes")` | eval HourOfDay=strftime(_time, "%H") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, "%w") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | join user HourOfDay isWeekend [ summary cloud_excessive_api_calls_v1] | where cardinality >=16 | apply cloud_excessive_api_calls_v1 threshold=0.005 | rename "IsOutlier(api_calls)" as isOutlier | where isOutlier=1 | eval expected_upper_threshold = mvindex(split(mvindex(BoundaryRanges, -1), ":"), 0) | where api_calls > expected_upper_threshold | eval distance_from_threshold = api_calls - expected_upper_threshold | table _time, user, command, api_calls, expected_upper_threshold, distance_from_threshold | `abnormally_high_number_of_cloud_infrastructure_api_calls_filter`

[ESCU - Abnormally High Number Of Cloud Instances Destroyed - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search finds for the number successfully destroyed cloud instances for every 4 hour block. This is split up between weekdays and the weekend. It then applies the probability densitiy model previously created and alerts on any outliers.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search finds for the number successfully destroyed cloud instances for every 4 hour block. This is split up between weekdays and the weekend. It then applies the probability densitiy model previously created and alerts on any outliers.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Instances Destroyed` to create the probability density function.
action.escu.known_false_positives = Many service accounts configured within a cloud infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2020-08-21
action.escu.modification_date = 2020-08-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Abnormally High Number Of Cloud Instances Destroyed - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Instance Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Abnormally High Number Of Cloud Instances Destroyed - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud Instance Activities"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats count as instances_destroyed values(All_Changes.object_id) as object_id from datamodel=Change where All_Changes.action=deleted AND All_Changes.status=success AND All_Changes.object_category=instance by All_Changes.user _time span=1h | `drop_dm_object_name("All_Changes")` | eval HourOfDay=strftime(_time, "%H") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, "%w") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | join HourOfDay isWeekend [summary cloud_excessive_instances_destroyed_v1] | where cardinality >=16 | apply cloud_excessive_instances_destroyed_v1 threshold=0.005 | rename "IsOutlier(instances_destroyed)" as isOutlier | where isOutlier=1 | eval expected_upper_threshold = mvindex(split(mvindex(BoundaryRanges, -1), ":"), 0) | eval distance_from_threshold = instances_destroyed - expected_upper_threshold | table _time, user, instances_destroyed, expected_upper_threshold, distance_from_threshold, object_id | `abnormally_high_number_of_cloud_instances_destroyed_filter`

[ESCU - Abnormally High Number Of Cloud Instances Launched - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search finds for the number successfully created cloud instances for every 4 hour block. This is split up between weekdays and the weekend. It then applies the probability densitiy model previously created and alerts on any outliers.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search finds for the number successfully created cloud instances for every 4 hour block. This is split up between weekdays and the weekend. It then applies the probability densitiy model previously created and alerts on any outliers.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Instances Launched` to create the probability density function.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2020-08-21
action.escu.modification_date = 2020-08-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Abnormally High Number Of Cloud Instances Launched - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining", "Suspicious Cloud Instance Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Abnormally High Number Of Cloud Instances Launched - Rule
action.correlationsearch.annotations = {"analytic_story": ["Cloud Cryptomining", "Suspicious Cloud Instance Activities"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats count as instances_launched values(All_Changes.object_id) as object_id from datamodel=Change where (All_Changes.action=created) AND All_Changes.status=success AND All_Changes.object_category=instance by All_Changes.user _time span=1h | `drop_dm_object_name("All_Changes")` | eval HourOfDay=strftime(_time, "%H") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, "%w") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | join HourOfDay isWeekend [summary cloud_excessive_instances_created_v1] | where cardinality >=16 | apply cloud_excessive_instances_created_v1 threshold=0.005 | rename "IsOutlier(instances_launched)" as isOutlier | where isOutlier=1 | eval expected_upper_threshold = mvindex(split(mvindex(BoundaryRanges, -1), ":"), 0) | eval distance_from_threshold = instances_launched - expected_upper_threshold | table _time, user, instances_launched, expected_upper_threshold, distance_from_threshold, object_id | `abnormally_high_number_of_cloud_instances_launched_filter`

[ESCU - Abnormally High Number Of Cloud Security Group API Calls - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect a spike in the number of API calls made to your cloud infrastructure environment about security groups by a user.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search will detect a spike in the number of API calls made to your cloud infrastructure environment about security groups by a user.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Security Group API Calls Per User` to create the probability density function model.
action.escu.known_false_positives = 
action.escu.creation_date = 2020-09-07
action.escu.modification_date = 2020-09-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Abnormally High Number Of Cloud Security Group API Calls - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud User Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 25
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Abnormally High Number Of Cloud Security Group API Calls - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud User Activities"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats count as security_group_api_calls values(All_Changes.command) as command from datamodel=Change where All_Changes.object_category=firewall AND All_Changes.status=success by All_Changes.user _time span=1h | `drop_dm_object_name("All_Changes")` | eval HourOfDay=strftime(_time, "%H") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, "%w") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | join user HourOfDay isWeekend [ summary cloud_excessive_security_group_api_calls_v1] | where cardinality >=16 | apply cloud_excessive_security_group_api_calls_v1 threshold=0.005 | rename "IsOutlier(security_group_api_calls)" as isOutlier | where isOutlier=1 | eval expected_upper_threshold = mvindex(split(mvindex(BoundaryRanges, -1), ":"), 0) | where security_group_api_calls > expected_upper_threshold | eval distance_from_threshold = security_group_api_calls - expected_upper_threshold | table _time, user, command, security_group_api_calls, expected_upper_threshold, distance_from_threshold | `abnormally_high_number_of_cloud_security_group_api_calls_filter`

[ESCU - Cloud API Calls From Previously Unseen User Roles - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for new commands from each user role.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for new commands from each user role.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud API Calls Per User Role - Initial` to build the initial table of user roles, commands, and times. You must also enable the second baseline search `Previously Seen Cloud API Calls Per User Role - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `cloud_api_calls_from_previously_unseen_user_roles_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_api_calls_from_previously_unseen_user_roles_filter`
action.escu.known_false_positives = .
action.escu.creation_date = 2020-09-04
action.escu.modification_date = 2020-09-04
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud API Calls From Previously Unseen User Roles - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud User Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 25
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud API Calls From Previously Unseen User Roles - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud User Activities"], "cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Change where All_Changes.user_type=AssumedRole AND All_Changes.status=success by All_Changes.user, All_Changes.command All_Changes.object | `drop_dm_object_name("All_Changes")` | lookup previously_seen_cloud_api_calls_per_user_role user as user, command as command OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenUserApiCall=min(firstTimeSeen) | where isnull(firstTimeSeenUserApiCall) OR firstTimeSeenUserApiCall > relative_time(now(),"-24h@h") | table firstTime, user, object, command |`security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `cloud_api_calls_from_previously_unseen_user_roles_filter`

[ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud compute instances created by users who have not created them before.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for cloud compute instances created by users who have not created them before.
action.escu.how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs Run the "Previously Seen Cloud Compute Creations By User" support search to create of baseline of previously seen users.
action.escu.known_false_positives = It's possible that a user will start to create compute instances for the first time, for any number of reasons. Verify with the user launching instances that this is the intended behavior.
action.escu.creation_date = 2020-08-21
action.escu.modification_date = 2020-08-21
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule
action.correlationsearch.annotations = {"analytic_story": ["Cloud Cryptomining"], "cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) as firstTime, latest(_time) as lastTime values(All_Changes.object) as dest from datamodel=Change where All_Changes.action=created by All_Changes.user All_Changes.vendor_region | `drop_dm_object_name("All_Changes")` | lookup previously_seen_cloud_compute_creations_by_user user as user OUTPUTNEW firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenUser=min(firstTimeSeen) | where isnull(firstTimeSeenUser) OR firstTimeSeenUser > relative_time(now(), "-24h@h") | table firstTime, user, dest, count vendor_region | `security_content_ctime(firstTime)` | `cloud_compute_instance_created_by_previously_unseen_user_filter`

[ESCU - Cloud Compute Instance Created In Previously Unused Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.
action.escu.mappings = {"cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Regions - Initial` to build the initial table of images observed and times. You must also enable the second baseline search `Previously Seen Cloud Regions - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_in_previously_unused_region_filter` macro.
action.escu.known_false_positives = It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.
action.escu.creation_date = 2020-09-02
action.escu.modification_date = 2020-09-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Compute Instance Created In Previously Unused Region - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Compute Instance Created In Previously Unused Region - Rule
action.correlationsearch.annotations = {"analytic_story": ["Cloud Cryptomining"], "cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime values(All_Changes.object_id) as dest, count from datamodel=Change where All_Changes.action=created by All_Changes.vendor_region, All_Changes.user | `drop_dm_object_name("All_Changes")` | lookup previously_seen_cloud_regions vendor_region as vendor_region OUTPUTNEW firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenRegion=min(firstTimeSeen) | where isnull(firstTimeSeenRegion) OR firstTimeSeenRegion > relative_time(now(), "-24h@h") | table firstTime, user, dest, count , vendor_region | `security_content_ctime(firstTime)` | `cloud_compute_instance_created_in_previously_unused_region_filter`

[ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud compute instances being created with previously unseen image IDs.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for cloud compute instances being created with previously unseen image IDs.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Compute Images - Initial` to build the initial table of images observed and times. You must also enable the second baseline search `Previously Seen Cloud Compute Images - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_with_previously_unseen_image_filter` macro.
action.escu.known_false_positives = After a new image is created, the first systems created with that image will cause this alert to fire.  Verify that the image being used was created by a legitimate user.
action.escu.creation_date = 2018-10-12
action.escu.modification_date = 2018-10-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule
action.correlationsearch.annotations = {"analytic_story": ["Cloud Cryptomining"], "cis20": ["CIS 1"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats count earliest(_time) as firstTime, latest(_time) as lastTime values(All_Changes.object_id) as dest from datamodel=Change where All_Changes.action=created by All_Changes.Instance_Changes.image_id, All_Changes.user | `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Instance_Changes")` | where image_id != "unknown" | lookup previously_seen_cloud_compute_images image_id as image_id OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenImage=min(firstTimeSeen) | where isnull(firstTimeSeenImage) OR firstTimeSeenImage > relative_time(now(), "-24h@h") | table firstTime, user, image_id, count, dest | `security_content_ctime(firstTime)` | `cloud_compute_instance_created_with_previously_unseen_image_filter`

[ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule]
action.escu = 0
action.escu.enabled = 1
description = Find EC2 instances being created with previously unseen instance types.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = Find EC2 instances being created with previously unseen instance types.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Compute Instance Types - Initial` to build the initial table of instance types observed and times. You must also enable the second baseline search `Previously Seen Cloud Compute Instance Types - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_with_previously_unseen_instance_type_filter` macro.
action.escu.known_false_positives = It is possible that an admin will create a new system using a new instance type that has never been used before. Verify with the creator that they intended to create the system with the new instance type.
action.escu.creation_date = 2020-09-12
action.escu.modification_date = 2020-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Cloud Cryptomining"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule
action.correlationsearch.annotations = {"analytic_story": ["Cloud Cryptomining"], "cis20": ["CIS 1"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime values(All_Changes.object_id) as dest, count from datamodel=Change where All_Changes.action=created by All_Changes.Instance_Changes.instance_type, All_Changes.user | `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Instance_Changes")` | where instance_type != "unknown" | lookup previously_seen_cloud_compute_instance_types instance_type as instance_type OUTPUTNEW firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenInstanceType=min(firstTimeSeen) | where isnull(firstTimeSeenInstanceType) OR firstTimeSeenInstanceType > relative_time(now(), "-24h@h") | table firstTime, user, dest, count, instance_type | `security_content_ctime(firstTime)` | `cloud_compute_instance_created_with_previously_unseen_instance_type_filter`

[ESCU - Cloud Instance Modified By Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud instances being modified by users who have not previously modified them.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for cloud instances being modified by users who have not previously modified them.
action.escu.how_to_implement = This search has a dependency on other searches to create and update a baseline of users observed to be associated with this activity. The search "Previously Seen Cloud Instance Modifications By User - Update" should be enabled for this detection to properly work.
action.escu.known_false_positives = It's possible that a new user will start to modify EC2 instances when they haven't before for any number of reasons. Verify with the user that is modifying instances that this is the intended behavior.
action.escu.creation_date = 2020-07-29
action.escu.modification_date = 2020-07-29
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Instance Modified By Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Instance Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Instance Modified By Previously Unseen User - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud Instance Activities"], "cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats `security_content_summariesonly` count earliest(_time) as firstTime, latest(_time) as lastTime values(All_Changes.object_id) as object_id values(All_Changes.command) as command from datamodel=Change where All_Changes.action=modified All_Changes.change_type=EC2 All_Changes.status=success by All_Changes.user | `drop_dm_object_name("All_Changes")` | lookup previously_seen_cloud_instance_modifications_by_user user as user OUTPUTNEW firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenUser=min(firstTimeSeen) | where isnull(firstTimeSeenUser) OR firstTimeSeenUser > relative_time(now(), "-24h@h") | table firstTime user command object_id count | `security_content_ctime(firstTime)` | `cloud_instance_modified_by_previously_unseen_user_filter`

[ESCU - Cloud Provisioning Activity From Previously Unseen City - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud provisioning activities from previously unseen cities. Provisioning activities are defined broadly as any event that runs or creates something.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for cloud provisioning activities from previously unseen cities. Provisioning activities are defined broadly as any event that runs or creates something.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_city_filter` macro.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2020-10-09
action.escu.modification_date = 2020-10-09
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Provisioning Activity From Previously Unseen City - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Provisioning Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Provisioning Activity From Previously Unseen City - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud Provisioning Activities"], "cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src, All_Changes.user, All_Changes.object, All_Changes.command | `drop_dm_object_name("All_Changes")` | iplocation src | where isnotnull(City) | lookup previously_seen_cloud_provisioning_activity_sources City as City OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenCity=min(firstTimeSeen) | where isnull(firstTimeSeenCity) OR firstTimeSeenCity > relative_time(now(), `previously_unseen_cloud_provisioning_activity_window`) | table firstTime, src, City, user, object, command | `cloud_provisioning_activity_from_previously_unseen_city_filter` | `security_content_ctime(firstTime)`

[ESCU - Cloud Provisioning Activity From Previously Unseen Country - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that runs or creates something.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for cloud provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that runs or creates something.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_country_filter` macro.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2020-10-09
action.escu.modification_date = 2020-10-09
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Provisioning Activity From Previously Unseen Country - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Provisioning Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 5
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Provisioning Activity From Previously Unseen Country - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud Provisioning Activities"], "cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src, All_Changes.user, All_Changes.object, All_Changes.command | `drop_dm_object_name("All_Changes")` | iplocation src | where isnotnull(Country) | lookup previously_seen_cloud_provisioning_activity_sources Country as Country OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenCountry=min(firstTimeSeen) | where isnull(firstTimeSeenCountry) OR firstTimeSeenCountry > relative_time(now(), "-24h@h") | table firstTime, src, Country, user, object, command | `cloud_provisioning_activity_from_previously_unseen_country_filter` | `security_content_ctime(firstTime)`

[ESCU - Cloud Provisioning Activity From Previously Unseen IP Address - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that runs or creates something.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for cloud provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that runs or creates something.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_ip_address_filter` macro.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2020-08-16
action.escu.modification_date = 2020-08-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Provisioning Activity From Previously Unseen IP Address - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Provisioning Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 5
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Provisioning Activity From Previously Unseen IP Address - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud Provisioning Activities"], "cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime, values(All_Changes.object_id) as object_id from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src, All_Changes.user, All_Changes.command | `drop_dm_object_name("All_Changes")` | lookup previously_seen_cloud_provisioning_activity_sources src as src OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenSrc=min(firstTimeSeen) | where isnull(firstTimeSeenSrc) OR firstTimeSeenSrc > relative_time(now(), `previously_unseen_cloud_provisioning_activity_window`) | table firstTime, src, user, object_id, command | `cloud_provisioning_activity_from_previously_unseen_ip_address_filter` | `security_content_ctime(firstTime)`

[ESCU - Cloud Provisioning Activity From Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cloud provisioning activities from previously unseen regions. Provisioning activities are defined broadly as any event that runs or creates something.
action.escu.mappings = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search looks for cloud provisioning activities from previously unseen regions. Provisioning activities are defined broadly as any event that runs or creates something.
action.escu.how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_region_filter` macro.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2020-08-16
action.escu.modification_date = 2020-08-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - Cloud Provisioning Activity From Previously Unseen Region - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Provisioning Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 5
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Cloud Provisioning Activity From Previously Unseen Region - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud Provisioning Activities"], "cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src, All_Changes.user, All_Changes.object, All_Changes.command | `drop_dm_object_name("All_Changes")` | iplocation src | where isnotnull(Region) | lookup previously_seen_cloud_provisioning_activity_sources Region as Region OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenRegion=min(firstTimeSeen) | where isnull(firstTimeSeenRegion) OR firstTimeSeenRegion > relative_time(now(), `previously_unseen_cloud_provisioning_activity_window`) | table firstTime, src, Region, user, object, command | `cloud_provisioning_activity_from_previously_unseen_region_filter` | `security_content_ctime(firstTime)`

[ESCU - Detect AWS Console Login by New User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2020-05-28
action.escu.modification_date = 2020-05-28
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect AWS Console Login by New User - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect AWS Console Login by New User - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious Cloud Authentication Activities"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user | `drop_dm_object_name(Authentication)` | inputlookup append=t previously_seen_users_console_logins | stats min(firstTime) as firstTime max(lastTime) as lastTime by user | eval userStatus=if(firstTime >=relative_time(now(),"-24h@h"), "First Time Logging into AWS Console", "Previously Seen User") |where userStatus="First Time Logging into AWS Console" |  `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `detect_aws_console_login_by_new_user_filter`

[ESCU - Detect AWS Console Login by User from New City - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_city_filter` macro.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2020-10-07
action.escu.modification_date = 2020-10-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New City - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 5
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect AWS Console Login by User from New City - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | `drop_dm_object_name(Authentication)` | table firstTime lastTime user City | join user  type=outer [| inputlookup previously_seen_users_console_logins | stats earliest(firstTime) AS earliestseen by user City | fields earliestseen user City] | eval userCity=if(firstTime >= relative_time(now(), "-24h@h"), "New City","Previously Seen City") | eval userStatus=if(earliestseen >= relative_time(now(), "-24h@h") OR isnull(earliestseen), "New User","Old User") | where userCity = "New City" AND userStatus != "Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime lastTime user City  userStatus userCity  | `detect_aws_console_login_by_user_from_new_city_filter`

[ESCU - Detect AWS Console Login by User from New Country - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_country_filter` macro.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2020-10-07
action.escu.modification_date = 2020-10-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New Country - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 5
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect AWS Console Login by User from New Country - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | `drop_dm_object_name(Authentication)` | table firstTime lastTime user Country | join user  type=outer [| inputlookup previously_seen_users_console_logins | stats earliest(firstTime) AS earliestseen by user Country | fields earliestseen user Country] | eval userCountry=if(firstTime >= relative_time(now(), "-24h@h"), "New Country","Previously Seen Country") | eval userStatus=if(earliestseen >= relative_time(now(),"-24h@h") OR isnull(earliestseen), "New User","Old User") | where userCountry = "New Country" AND userStatus != "Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime lastTime user Country  userStatus userCountry  | `detect_aws_console_login_by_user_from_new_country_filter`

[ESCU - Detect AWS Console Login by User from New Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_region_filter` macro.
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2020-10-07
action.escu.modification_date = 2020-10-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect AWS Console Login by User from New Region - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 5
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect AWS Console Login by User from New Region - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | `drop_dm_object_name(Authentication)` | table firstTime lastTime user Region | join user  type=outer [| inputlookup previously_seen_users_console_logins | stats earliest(firstTime) AS earliestseen by user Region | fields earliestseen user Region] | eval userRegion=if(firstTime >= relative_time(now(), "-24h@h"), "New Region","Previously Seen Region") | eval userStatus=if(earliestseen >= relative_time(now(), "-24h@h") OR isnull(earliestseen), "New User","Old User") | where userRegion = "New Region" AND userStatus != "Old User" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime lastTime user Region  userStatus userRegion  | `detect_aws_console_login_by_user_from_new_region_filter`

[ESCU - Detect New Open S3 Buckets over AWS CLI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user has created an open/public S3 bucket over the aws cli.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user has created an open/public S3 bucket over the aws cli.
action.escu.how_to_implement = 
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the "All Users" group.
action.escu.creation_date = 2021-01-12
action.escu.modification_date = 2021-01-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect New Open S3 Buckets over AWS CLI - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect New Open S3 Buckets over AWS CLI - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious AWS S3 Activities"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventSource="s3.amazonaws.com" eventName=PutBucketAcl OR requestParameters.accessControlList.x-amz-grant-read-acp IN ("*AuthenticatedUsers","*AllUsers") OR requestParameters.accessControlList.x-amz-grant-write IN ("*AuthenticatedUsers","*AllUsers") OR requestParameters.accessControlList.x-amz-grant-write-acp IN ("*AuthenticatedUsers","*AllUsers") OR requestParameters.accessControlList.x-amz-grant-full-control IN ("*AuthenticatedUsers","*AllUsers") | rename requestParameters.bucketName AS bucketName | fillnull | stats count min(_time) as firstTime max(_time) as lastTime by userName userIdentity.principalId userAgent bucketName requestParameters.accessControlList.x-amz-grant-read requestParameters.accessControlList.x-amz-grant-read-acp requestParameters.accessControlList.x-amz-grant-write requestParameters.accessControlList.x-amz-grant-write-acp requestParameters.accessControlList.x-amz-grant-full-control | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_new_open_s3_buckets_over_aws_cli_filter` 

[ESCU - Detect New Open S3 buckets - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user has created an open/public S3 bucket.
action.escu.mappings = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for CloudTrail events where a user has created an open/public S3 bucket.
action.escu.how_to_implement = You must install the AWS App for Splunk.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the "All Users" group.
action.escu.creation_date = 2021-01-12
action.escu.modification_date = 2021-01-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect New Open S3 buckets - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect New Open S3 buckets - Rule
action.correlationsearch.annotations = {"analytic_story": ["Suspicious AWS S3 Activities"], "cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `cloudtrail` eventSource=s3.amazonaws.com eventName=PutBucketAcl | rex field=_raw "(?<json_field>{.+})" | spath input=json_field output=grantees path=requestParameters.AccessControlPolicy.AccessControlList.Grant{} | search grantees=* | mvexpand grantees | spath input=grantees output=uri path=Grantee.URI | spath input=grantees output=permission path=Permission | search uri IN ("http://acs.amazonaws.com/groups/global/AllUsers","http://acs.amazonaws.com/groups/global/AuthenticatedUsers") | search permission IN ("READ","READ_ACP","WRITE","WRITE_ACP","FULL_CONTROL") | rename requestParameters.bucketName AS bucketName | stats count min(_time) as firstTime max(_time) as lastTime by userName userIdentity.principalId userAgent uri permission bucketName | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_new_open_s3_buckets_filter` 

[ESCU - Detect Spike in AWS Security Hub Alerts for EC2 Instance - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for a spike in number of of AWS security Hub alerts for an EC2 instance in 4 hours intervals
action.escu.mappings = {"cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search looks for a spike in number of of AWS security Hub alerts for an EC2 instance in 4 hours intervals
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Security Hub inputs. The threshold_value should be tuned to your environment and schedule these searches according to the bucket span interval.
action.escu.known_false_positives = None
action.escu.creation_date = 2021-01-26
action.escu.modification_date = 2021-01-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Spike in AWS Security Hub Alerts for EC2 Instance - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["AWS Security Hub Alerts"]
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - Detect Spike in AWS Security Hub Alerts for EC2 Instance - Rule
action.correlationsearch.annotations = {"analytic_story": ["AWS Security Hub Alerts"], "cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `aws_securityhub_finding` "Resources{}.Type"=AWSEC2Instance | bucket span=4h _time | stats count AS alerts values(Title) as Title values(Types{}) as Types values(vendor_account) as vendor_account values(vendor_region) as vendor_region values(severity) as severity by _time dest | eventstats avg(alerts) as total_alerts_avg, stdev(alerts) as total_alerts_stdev | eval threshold_value = 3 | eval isOutlier=if(alerts > total_alerts_avg+(total_alerts_stdev * threshold_value), 1, 0) | search isOutlier=1 | table _time dest alerts Title Types vendor_account vendor_region severity isOutlier total_alerts_avg | `detect_spike_in_aws_security_hub_alerts_for_ec2_instance_filter`

[ESCU - O365 Add App Role Assignment Grant User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the creation of a new Federation setting by alerting about an specific event related to its creation.
action.escu.mappings = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
action.escu.data_models = []
action.escu.eli5 = This search detects the creation of a new Federation setting by alerting about an specific event related to its creation.
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = The creation of a new Federation is not necessarily malicious, however this events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a different cloud provider.
action.escu.creation_date = 2021-01-26
action.escu.modification_date = 2021-01-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Add App Role Assignment Grant User - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections", "Cloud Federated Credential Abuse"]
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Add App Role Assignment Grant User - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections", "Cloud Federated Credential Abuse"], "kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Workload=AzureActiveDirectory Operation="Add app role assignment grant to user." | stats count min(_time) as firstTime max(_time) as lastTime values(Actor{}.ID) as Actor.ID values(Actor{}.Type) as Actor.Type by ActorIpAddress dest ResultStatus | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `o365_add_app_role_assignment_grant_user_filter`

[ESCU - O365 Added Service Principal - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the creation of a new Federation setting by alerting about an specific event related to its creation.
action.escu.mappings = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
action.escu.data_models = []
action.escu.eli5 = This search detects the creation of a new Federation setting by alerting about an specific event related to its creation.
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = The creation of a new Federation is not necessarily malicious, however these events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a different cloud provider.
action.escu.creation_date = 2021-01-26
action.escu.modification_date = 2021-01-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Added Service Principal - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections", "Cloud Federated Credential Abuse"]
action.risk = 1
action.risk.param._risk_object = ActorIpAddress
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Added Service Principal - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections", "Cloud Federated Credential Abuse"], "kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Workload=AzureActiveDirectory signature="Add service principal credentials." | stats min(_time) as firstTime max(_time) as lastTime values(Actor{}.ID) as Actor.ID values(ModifiedProperties{}.Name) as ModifiedProperties.Name values(ModifiedProperties{}.NewValue) as ModifiedProperties.NewValue values(Target{}.ID) as Target.ID by ActorIpAddress signature | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `o365_added_service_principal_filter`

[ESCU - O365 Bypass MFA via Trusted IP - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects newly added IP addresses/CIDR blocks to the list of MFA Trusted IPs to bypass multi factor authentication. Attackers are often known to use this technique so that they can bypass the MFA system.
action.escu.mappings = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1562.007"]}
action.escu.data_models = []
action.escu.eli5 = This search detects newly added IP addresses/CIDR blocks to the list of MFA Trusted IPs to bypass multi factor authentication. Attackers are often known to use this technique so that they can bypass the MFA system.
action.escu.how_to_implement = You must install Splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = Unless it is a special case, it is uncommon to continually update Trusted IPs to MFA configuration.
action.escu.creation_date = 2021-01-12
action.escu.modification_date = 2021-01-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Bypass MFA via Trusted IP - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Bypass MFA via Trusted IP - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections"], "kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1562.007"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` signature="Set Company Information." ModifiedProperties{}.Name=StrongAuthenticationPolicy | rex max_match=100 field=ModifiedProperties{}.NewValue "(?<ip_addresses_new_added>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\/\d{1,2})" | rex max_match=100 field=ModifiedProperties{}.OldValue "(?<ip_addresses_old>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\/\d{1,2})" | eval ip_addresses_old=if(isnotnull(ip_addresses_old),ip_addresses_old,"0") | mvexpand ip_addresses_new_added | where isnull(mvfind(ip_addresses_old,ip_addresses_new_added)) |stats count min(_time) as firstTime max(_time) as lastTime values(ip_addresses_old) as ip_addresses_old by user ip_addresses_new_added signature vendor_product vendor_account status user_id action | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `o365_bypass_mfa_via_trusted_ip_filter`

[ESCU - O365 Disable MFA - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects when multi factor authentication has been disabled, what entitiy performed the action and against what user
action.escu.mappings = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1556"]}
action.escu.data_models = []
action.escu.eli5 = This search detects when multi factor authentication has been disabled, what entitiy performed the action and against what user
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = Unless it is a special case, it is uncommon to disable MFA or Strong Authentication
action.escu.creation_date = 2020-12-16
action.escu.modification_date = 2020-12-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Disable MFA - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections"]
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Disable MFA - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections"], "kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1556"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Operation="Disable Strong Authentication." | stats count earliest(_time) as firstTime latest(_time) as lastTime by UserType Operation user status signature dest ResultStatus |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `o365_disable_mfa_filter`

[ESCU - O365 Excessive Authentication Failures Alert - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects when an excessive number of authentication failures occur this search also includes attempts against MFA prompt codes
action.escu.mappings = {"kill_chain_phases": ["Not Applicable"], "mitre_attack": ["T1110"]}
action.escu.data_models = []
action.escu.eli5 = This search detects when an excessive number of authentication failures occur this search also includes attempts against MFA prompt codes
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = The threshold for alert is above 10 attempts and this should reduce the number of false positives.
action.escu.creation_date = 2020-12-16
action.escu.modification_date = 2020-12-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Excessive Authentication Failures Alert - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Excessive Authentication Failures Alert - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections"], "kill_chain_phases": ["Not Applicable"], "mitre_attack": ["T1110"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Workload=AzureActiveDirectory UserAuthenticationMethod=* status=Failed | stats count earliest(_time) as firstTime latest(_time) values(UserAuthenticationMethod) AS UserAuthenticationMethod values(UserAgent) AS UserAgent values(status) AS status values(src_ip) AS src_ip by user | where count > 10 |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `o365_excessive_authentication_failures_alert_filter`

[ESCU - O365 Excessive SSO logon errors - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects accounts with high number of Single Sign ON (SSO) logon errors. Excessive logon errors may indicate attempts to bruteforce of password or single sign on token hijack or reuse.
action.escu.mappings = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1556"]}
action.escu.data_models = []
action.escu.eli5 = This search detects accounts with high number of Single Sign ON (SSO) logon errors. Excessive logon errors may indicate attempts to bruteforce of password or single sign on token hijack or reuse.
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = Logon errors may not be malicious in nature however it may indicate attempts to reuse a token or password obtained via credential access attack.
action.escu.creation_date = 2021-01-26
action.escu.modification_date = 2021-01-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Excessive SSO logon errors - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections", "Cloud Federated Credential Abuse"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Excessive SSO logon errors - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections", "Cloud Federated Credential Abuse"], "kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1556"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity`  Workload=AzureActiveDirectory LogonError=SsoArtifactInvalidOrExpired | stats count min(_time) as firstTime max(_time) as lastTime by LogonError ActorIpAddress UserAgent UserId | where count > 5 | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `o365_excessive_sso_logon_errors_filter`

[ESCU - O365 New Federated Domain Added - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the addition of a new Federated domain.
action.escu.mappings = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
action.escu.data_models = []
action.escu.eli5 = This search detects the addition of a new Federated domain.
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity.
action.escu.known_false_positives = The creation of a new Federated domain is not necessarily malicious, however these events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a similar or different cloud provider.
action.escu.creation_date = 2021-01-26
action.escu.modification_date = 2021-01-26
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 New Federated Domain Added - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections", "Cloud Federated Credential Abuse"]
action.risk = 1
action.risk.param._risk_object = UserId
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 New Federated Domain Added - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections", "Cloud Federated Credential Abuse"], "kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Workload=Exchange Operation="Add-FederatedDomain" | stats count min(_time) as firstTime max(_time) as lastTime values(Parameters{}.Value) as Parameters.Value by ObjectId Operation OrganizationName OriginatingServer UserId UserKey | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_new_federated_domain_added_filter`

[ESCU - O365 PST export alert - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects when a user has performed an Ediscovery search or exported a PST file from the search. This PST file usually has sensitive information including email body content
action.escu.mappings = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1114"]}
action.escu.data_models = []
action.escu.eli5 = This search detects when a user has performed an Ediscovery search or exported a PST file from the search. This PST file usually has sensitive information including email body content
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = PST export can be done for legitimate purposes but due to the sensitive nature of its content it must be monitored.
action.escu.creation_date = 2020-12-16
action.escu.modification_date = 2020-12-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 PST export alert - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections"]
action.risk = 1
action.risk.param._risk_object = Source
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 PST export alert - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections"], "kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1114"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Category=ThreatManagement Name="eDiscovery search started or exported" | stats count earliest(_time) as firstTime latest(_time) as lastTime by Source Severity AlertEntityId Operation Name |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `o365_pst_export_alert_filter`

[ESCU - O365 Suspicious Admin Email Forwarding - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects when an admin configured a forwarding rule for multiple mailboxes to the same destination.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.003"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search detects when an admin configured a forwarding rule for multiple mailboxes to the same destination.
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = unknown
action.escu.creation_date = 2020-12-16
action.escu.modification_date = 2020-12-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Suspicious Admin Email Forwarding - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections"]
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Suspicious Admin Email Forwarding - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.003"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Operation=Set-Mailbox | spath input=Parameters | rename Identity AS src_user | search ForwardingAddress=* | stats dc(src_user) AS count_src_user earliest(_time) as firstTime latest(_time) as lastTime values(src_user) AS src_user values(user) AS user by ForwardingAddress | where count_src_user > 1 |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` |`o365_suspicious_admin_email_forwarding_filter`

[ESCU - O365 Suspicious Rights Delegation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the assignment of rights to accesss content from another mailbox. This is usually only assigned to a service account.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.002"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search detects the assignment of rights to accesss content from another mailbox. This is usually only assigned to a service account.
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = Service Accounts
action.escu.creation_date = 2020-12-15
action.escu.modification_date = 2020-12-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Suspicious Rights Delegation - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections"]
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Suspicious Rights Delegation - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.002"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Operation=Add-MailboxPermission | spath input=Parameters | rename User AS src_user, Identity AS dest_user | search AccessRights=FullAccess OR AccessRights=SendAs OR AccessRights=SendOnBehalf | stats count earliest(_time) as firstTime latest(_time) as lastTime by user src_user dest_user Operation AccessRights |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` |`o365_suspicious_rights_delegation_filter`

[ESCU - O365 Suspicious User Email Forwarding - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects when multiple user configured a forwarding rule to the same destination.
action.escu.mappings = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.003"], "nist": ["DE.DP", "DE.AE"]}
action.escu.data_models = []
action.escu.eli5 = This search detects when multiple user configured a forwarding rule to the same destination.
action.escu.how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
action.escu.known_false_positives = unknown
action.escu.creation_date = 2020-12-16
action.escu.modification_date = 2020-12-16
action.escu.confidence = high
action.escu.full_search_name = ESCU - O365 Suspicious User Email Forwarding - Rule
action.escu.search_type = detection
action.escu.product = ["Splunk Security Analytics for AWS", "Splunk Enterprise", "Splunk Enterprise Security", "Splunk Cloud"]
action.escu.providing_technologies = []
action.escu.analytic_story = ["Office 365 Detections"]
action.risk = 1
action.risk.param._risk_object = ForwardingSmtpAddress
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = ESCU - O365 Suspicious User Email Forwarding - Rule
action.correlationsearch.annotations = {"analytic_story": ["Office 365 Detections"], "cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.003"], "nist": ["DE.DP", "DE.AE"]}
schedule_window = auto
alert.digest_mode = 1
disabled = true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
is_visible = false
search = `o365_management_activity` Operation=Set-Mailbox | spath input=Parameters | rename Identity AS src_user | search ForwardingSmtpAddress=* | stats dc(src_user) AS count_src_user earliest(_time) as firstTime latest(_time) as lastTime values(src_user) AS src_user values(user) AS user by ForwardingSmtpAddress | where count_src_user > 1 |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` |`o365_suspicious_user_email_forwarding_filter`

### END ESCU DETECTIONS ###


### ESCU BASELINES ###

[ESCU - Baseline Of Cloud Infrastructure API Calls Per User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline Of Cloud Infrastructure API Calls Per User
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many API calls are performed by each user. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances created in a small time window.
action.escu.creation_date = 2020-09-07
action.escu.modification_date = 2020-09-07
action.escu.analytic_story = ["Suspicious Cloud User Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 0 2 * * 0
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model for how many API calls are performed by each user. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances created in a small time window.
action.escu.how_to_implement = You must have Enterprise Security 6.0 or later, if not you will need to verify that the Machine Learning Toolkit (MLTK) version 4.2 or later is installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 90 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.
disabled = true
is_visible = false
search = | tstats count as api_calls from datamodel=Change where All_Changes.user!=unknown All_Changes.status=success by All_Changes.user _time span=1h | `drop_dm_object_name("All_Changes")` | eval HourOfDay=strftime(_time, "%H") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, "%w") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | table _time api_calls, user, HourOfDay, isWeekend | eventstats dc(api_calls) as api_calls by user, HourOfDay, isWeekend | where api_calls >= 1 | fit DensityFunction api_calls by "user,HourOfDay,isWeekend" into cloud_excessive_api_calls_v1 dist=norm show_density=true

[ESCU - Baseline Of Cloud Instances Destroyed]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline Of Cloud Instances Destroyed
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many instances are destroyed in the environment. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances destroyed in a small time window.
action.escu.creation_date = 2020-08-25
action.escu.modification_date = 2020-08-25
action.escu.analytic_story = ["Suspicious Cloud Instance Activities", "Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 0 2 * * 0
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model for how many instances are destroyed in the environment. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances destroyed in a small time window.
action.escu.how_to_implement = You must have Enterprise Security 6.0 or later, if not you will need to verify that the Machine Learning Toolkit (MLTK) version 4.2 or later is installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = | tstats count as instances_destroyed from datamodel=Change where All_Changes.action=deleted AND All_Changes.status=success AND All_Changes.object_category=instance by _time span=1h | makecontinuous span=1h _time | eval instances_destroyed=coalesce(instances_destroyed, (random()%2)*0.0000000001) | eval HourOfDay=strftime(_time, "%H") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, "%w") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | table _time instances_destroyed, HourOfDay, isWeekend | fit DensityFunction instances_destroyed by "HourOfDay,isWeekend" into cloud_excessive_instances_destroyed_v1 dist=expon show_density=true

[ESCU - Baseline Of Cloud Instances Launched]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline Of Cloud Instances Launched
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many instances are created in the environment. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances created in a small time window.
action.escu.creation_date = 2020-08-14
action.escu.modification_date = 2020-08-14
action.escu.analytic_story = ["Cloud Cryptomining", "Suspicious Cloud Instance Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 0 2 * * 0
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model for how many instances are created in the environment. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances created in a small time window.
action.escu.how_to_implement = You must have Enterprise Security 6.0 or later, if not you will need to verify that the Machine Learning Toolkit (MLTK) version 4.2 or later is installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 90 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = | tstats count as instances_launched from datamodel=Change where (All_Changes.action=created) AND All_Changes.status=success AND All_Changes.object_category=instance by _time span=1h | makecontinuous span=1h _time | eval instances_launched=coalesce(instances_launched, (random()%2)*0.0000000001) | eval HourOfDay=strftime(_time, "%H") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, "%w") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | table _time instances_launched, HourOfDay, isWeekend | fit DensityFunction instances_launched by "HourOfDay,isWeekend" into cloud_excessive_instances_created_v1 dist=expon show_density=true

[ESCU - Baseline Of Cloud Security Group API Calls Per User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline Of Cloud Security Group API Calls Per User
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many API calls for security groups are performed by each user. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly.
action.escu.creation_date = 2020-09-07
action.escu.modification_date = 2020-09-07
action.escu.analytic_story = ["Suspicious Cloud User Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 0 2 * * 0
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model for how many API calls for security groups are performed by each user. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly.
action.escu.how_to_implement = You must have Enterprise Security 6.0 or later, if not you will need to verify that the Machine Learning Toolkit (MLTK) version 4.2 or later is installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 90 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.
disabled = true
is_visible = false
search = | tstats count as security_group_api_calls from datamodel=Change where All_Changes.object_category=firewall All_Changes.status=success by All_Changes.user _time span=1h | `drop_dm_object_name("All_Changes")` | eval HourOfDay=strftime(_time, "%H") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, "%w") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | table _time security_group_api_calls, user, HourOfDay, isWeekend | eventstats dc(security_group_api_calls) as security_group_api_calls by user, HourOfDay, isWeekend | where security_group_api_calls >= 1 | fit DensityFunction security_group_api_calls by "user,HourOfDay,isWeekend" into cloud_excessive_security_group_api_calls_v1 dist=norm show_density=true

[ESCU - Baseline of API Calls per User ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of API Calls per User ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventType=AwsApiCall | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | stats count

[ESCU - Baseline of Command Line Length - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Command Line Length - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the command lines observed for each user in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies outliers in the length of the command line.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Unusual Processes"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the command lines observed for each user in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies outliers in the length of the command line.
action.escu.how_to_implement = You must be ingesting endpoint data and populating the Endpoint data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as start_time max(_time) as end_time FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name(Processes)` | search user!=unknown | `security_content_ctime(start_time)`| `security_content_ctime(end_time)`| eval processlen=len(process) | fit DensityFunction processlen by user into cmdline_pdfmodel

[ESCU - Baseline of DNS Query Length - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of DNS Query Length - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the DNS queries for each DNS record type observed in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which uses it to identify outliers in the length of the DNS query.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["Command and Control", "Hidden Cobra Malware", "Suspicious DNS Traffic"]
action.escu.data_models = ["Network_Resolution"]
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the DNS queries for each DNS record type observed in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which uses it to identify outliers in the length of the DNS query.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Resolution by DNS.query DNS.record_type | search DNS.record_type=* | `drop_dm_object_name("DNS")` | eval query_length = len(query) | fit DensityFunction query_length by record_type into dns_query_pdfmodel

[ESCU - Baseline of Excessive AWS Instances Launched by User - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Excessive AWS Instances Launched by User - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many RunInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of RunInstances performed by a user in a small time window.
action.escu.creation_date = 2019-11-14
action.escu.modification_date = 2019-11-14
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model for how many RunInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of RunInstances performed by a user in a small time window.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.\
In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success `ec2_excessive_runinstances_mltk_input_filter` | bucket span=10m _time | stats count as instances_launched by _time src_user | fit DensityFunction instances_launched threshold=0.0005 into ec2_excessive_runinstances_v1

[ESCU - Baseline of Excessive AWS Instances Terminated by User - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Excessive AWS Instances Terminated by User - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model for how many TerminateInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of TerminateInstances performed by a user in a small time window.
action.escu.creation_date = 2019-11-14
action.escu.modification_date = 2019-11-14
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model for how many TerminateInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of TerminateInstances performed by a user in a small time window.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.\
In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = `cloudtrail` eventName=TerminateInstances errorCode=success `ec2_excessive_terminateinstances_mltk_input_filter` | bucket span=10m _time | stats count as instances_terminated by _time src_user | fit DensityFunction instances_terminated threshold=0.0005 into ec2_excessive_terminateinstances_v1

[ESCU - Baseline of Network ACL Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Network ACL Activity by ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls that were related to network ACLs made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-05-21
action.escu.modification_date = 2018-05-21
action.escu.analytic_story = ["AWS Network ACL Activity"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls that were related to network ACLs made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for network ACLs, edit the macro `network_acl_events`.
disabled = true
is_visible = false
search = `cloudtrail` `network_acl_events` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup network_acl_activity_baseline | stats count

[ESCU - Baseline of S3 Bucket deletion activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of S3 Bucket deletion activity by ARN
description = This search establishes, on a per-hour basis, the average and standard deviation for the number of API calls related to deleting an S3 bucket by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-07-17
action.escu.modification_date = 2018-07-17
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and standard deviation for the number of API calls related to deleting an S3 bucket by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventName=DeleteBucket | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | stats count

[ESCU - Baseline of SMB Traffic - MLTK]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of SMB Traffic - MLTK
description = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the number of SMB connections observed each hour for every day of week. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search to identify outliers in the number of SMB connections for that hour and day of the week.
action.escu.creation_date = 2019-05-08
action.escu.modification_date = 2019-05-08
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Netsh Abuse", "Ransomware"]
action.escu.data_models = ["Network_Traffic"]
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the number of SMB connections observed each hour for every day of week. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search to identify outliers in the number of SMB connections for that hour and day of the week.
action.escu.how_to_implement = You must be ingesting network traffic and populating the Network_Traffic data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. To improve your results, you may consider adding "src" to the by clause, which will build the model for each unique source in your enviornment. However, if you have a large number of hosts in your environment, this search may be very resource intensive. In this case, you may need to raise the value of max_inputs and/or max_groups in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=10m, All_Traffic.src | eval HourOfDay=strftime(_time, "%H") | eval DayOfWeek=strftime(_time, "%A") | `drop_dm_object_name("All_Traffic")` | fit DensityFunction count by "HourOfDay,DayOfWeek" into smb_pdfmodel

[ESCU - Baseline of Security Group Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Security Group Activity by ARN
description = This search establishes, on a per-hour basis, the average and the standard deviation for the number of API calls related to security groups made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-17
action.escu.modification_date = 2018-04-17
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and the standard deviation for the number of API calls related to security groups made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for security groups, edit the macro `security_group_api_calls`.
disabled = true
is_visible = false
search = `cloudtrail` `security_group_api_calls` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | stats count

[ESCU - Baseline of blocked outbound traffic from AWS]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of blocked outbound traffic from AWS
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of outbound connections blocked in your VPC flow logs by each source IP address (IP address of your EC2 instances). Also recorded is the number of data points for each source IP. This table outputs to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-05-07
action.escu.modification_date = 2018-05-07
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search establishes, on a per-hour basis, the average and the standard deviation of the number of outbound connections blocked in your VPC flow logs by each source IP address (IP address of your EC2 instances). Also recorded is the number of data points for each source IP. This table outputs to a lookup file to allow the detection search to operate quickly.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your `VPC flow logs.`.
disabled = true
is_visible = false
search = `cloudwatchlogs_vpcflow` action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | bucket _time span=1h | stats count as numberOfBlockedConnections by _time, src_ip | stats count(numberOfBlockedConnections) as numDataPoints, latest(numberOfBlockedConnections) as latestCount, avg(numberOfBlockedConnections) as avgBlockedConnections, stdev(numberOfBlockedConnections) as stdevBlockedConnections by src_ip | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | stats count

[ESCU - Count of Unique IPs Connecting to Ports]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Count of Unique IPs Connecting to Ports
description = The search counts the number of times a connection was observed to each destination port, and the number of unique source IPs connecting to them.
action.escu.creation_date = 2017-09-13
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = []
action.escu.data_models = ["Network_Traffic"]
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = The search counts the number of times a connection was observed to each destination port, and the number of unique source IPs connecting to them.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting network traffic, and populating the Network_Traffic data model.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count dc(All_Traffic.src) as numberOfUniqueHosts from datamodel=Network_Traffic by All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Count of assets by category]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Count of assets by category
description = This search shows you every asset category you have and the assets that belong to those categories.
action.escu.creation_date = 2017-09-13
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Asset Tracking"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search shows you every asset category you have and the assets that belong to those categories.
action.escu.how_to_implement = To successfully implement this search you must first leverage the Assets and Identity framework in Enterprise Security to populate your assets_by_str.csv file which should then be mapped to the Identity_Management data model. The Identity_Management data model will contain a list of known authorized company assets. Ensure that all inventoried systems are constantly vetted and updated.
disabled = true
is_visible = false
search = | from datamodel Identity_Management.All_Assets | stats count values(nt_host) by category | sort -count

[ESCU - Create a list of approved AWS service accounts]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Create a list of approved AWS service accounts
description = This search looks for successful API activity in CloudTrail within the last 30 days, filters out known users from the identity table, and outputs values of users into `aws_service_accounts.csv` lookup file.
action.escu.creation_date = 2018-12-03
action.escu.modification_date = 2018-12-03
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for successful API activity in CloudTrail within the last 30 days, filters out known users from the identity table, and outputs values of users into `aws_service_accounts.csv` lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the service account entires in `aws_service_accounts.csv`, which is a lookup file created as a result of running this support search. Please remove the entries of service accounts that are not legitimate.
disabled = true
is_visible = false
search = `cloudtrail` errorCode=success | rename userName as identity | search NOT [inputlookup identity_lookup_expanded | fields identity] | stats count by identity | table identity | outputlookup aws_service_accounts | stats count

[ESCU - DNSTwist Domain Names]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - DNSTwist Domain Names
description = This search creates permutations of your existing domains, removes the valid domain names and stores them in a specified lookup file so they can be checked for in the associated detection searches.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search creates permutations of your existing domains, removes the valid domain names and stores them in a specified lookup file so they can be checked for in the associated detection searches.
action.escu.how_to_implement = To successfully implement this search you need to update the file called domains.csv in the DA-ESS-SOC/lookup directory. Or `cim_corporate_email_domains.csv` and `cim_corporate_web_domains.csv` from **Splunk\_SA\_CIM**.
disabled = true
is_visible = false
search = | dnstwist domainlist=domains.csv | `remove_valid_domains` | eval domain_abuse="true" | table domain, domain_abuse | outputlookup brandMonitoring_lookup | stats count

[ESCU - Discover DNS records]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Discover DNS records
description = The search takes corporate and common cloud provider domains configured under `cim_corporate_email_domains.csv`, `cim_corporate_web_domains.csv`, and `cloud_domains.csv` finds their responses across the last 30 days from data in the `Network_Resolution ` datamodel, then stores the output under the `discovered_dns_records.csv` lookup
action.escu.creation_date = 2019-02-14
action.escu.modification_date = 2019-02-14
action.escu.analytic_story = ["DNS Hijacking"]
action.escu.data_models = ["Network_Resolution"]
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = The search takes corporate and common cloud provider domains configured under `cim_corporate_email_domains.csv`, `cim_corporate_web_domains.csv`, and `cloud_domains.csv` finds their responses across the last 30 days from data in the `Network_Resolution ` datamodel, then stores the output under the `discovered_dns_records.csv` lookup
action.escu.how_to_implement = To successfully implement this search, you must be ingesting DNS logs, and populating the Network_Resolution data model. Also make sure that the cim_corporate_web_domains and cim_corporate_email_domains lookups are populated with the domains owned by your corporation
disabled = true
is_visible = false
search = | inputlookup cim_corporate_email_domains.csv | inputlookup append=T cim_corporate_web_domains.csv | inputlookup append=T cim_cloud_domains.csv | eval domain = trim(replace(domain, "\*", "")) | join domain [|tstats `security_content_summariesonly` count values(DNS.record_type) as type, values(DNS.answer) as answer from datamodel=Network_Resolution where DNS.message_type=RESPONSE DNS.answer!="unknown" DNS.answer!="" by DNS.query | rename DNS.query as query | where query!="unknown" | rex field=query "(?<domain>\w+\.\w+?)(?:$|/)"] | makemv delim=" " answer |  makemv delim=" " type | sort -count | table count,domain,type,query,answer | outputlookup createinapp=true discovered_dns_records

[ESCU - Identify Systems Creating Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Creating Remote Desktop Traffic
description = This search counts the numbers of times the system has generated remote desktop traffic.
action.escu.creation_date = 2017-09-15
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = []
action.escu.data_models = ["Network_Traffic"]
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search counts the numbers of times the system has generated remote desktop traffic.
action.escu.how_to_implement = To successfully implement this search, you must ingest network traffic and populate the Network_Traffic data model.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.src | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Identify Systems Receiving Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Receiving Remote Desktop Traffic
description = This search counts the numbers of times the system has created remote desktop traffic
action.escu.creation_date = 2017-09-15
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = []
action.escu.data_models = ["Network_Traffic"]
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search counts the numbers of times the system has created remote desktop traffic
action.escu.how_to_implement = To successfully implement this search you must ingest network traffic and populate the Network_Traffic data model. If a system receives a lot of remote desktop traffic, you can apply the category common_rdp_destination to it.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.dest | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Identify Systems Using Remote Desktop]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Using Remote Desktop
description = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = []
action.escu.data_models = ["Endpoint"]
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system.
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data that records process activity.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count from datamodel=Endpoint.Processes where Processes.process_name="*mstsc.exe*" by Processes.dest Processes.process_name | `drop_dm_object_name(Processes)` | sort - count

[ESCU - Monitor Successful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Monitor Successful Backups
description = This search is intended to give you a feel for how often successful backups are conducted in your environment. Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is intended to give you a feel for how often successful backups are conducted in your environment. Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
disabled = true
is_visible = false
search = `netbackup` "Disk/Partition backup completed successfully." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Monitor Unsuccessful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Monitor Unsuccessful Backups
description = This search is intended to give you a feel for how often backup failures happen in your environments.  Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is intended to give you a feel for how often backup failures happen in your environments.  Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
disabled = true
is_visible = false
search = `netbackup` "An error occurred, failed to backup." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Previously Seen AWS Cross Account Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Cross Account Activity
description = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.creation_date = 2018-06-04
action.escu.modification_date = 2018-06-04
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
disabled = true
is_visible = false
search = `cloudtrail` eventName=AssumeRole | spath output=requestingAccountId path=userIdentity.accountId | spath output=requestedAccountId path=resources{}.accountId | search requestingAccountId=* | where requestingAccountId!=requestedAccountId | stats earliest(_time) as firstTime latest(_time) as lastTime by requestingAccountId, requestedAccountId | outputlookup previously_seen_aws_cross_account_activity | stats count

[ESCU - Previously Seen AWS Cross Account Activity - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Cross Account Activity - Initial
description = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.creation_date = 2020-08-15
action.escu.modification_date = 2020-08-15
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
action.escu.data_models = ["Authentication"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later)and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=AssumeRole by Authentication.vendor_account Authentication.user Authentication.src Authentication.user_role |  `drop_dm_object_name(Authentication)` | rex field=user_role "arn:aws:sts:*:(?<dest_account>.*):" |  where  vendor_account != dest_account | rename vendor_account as requestingAccountId dest_account as requestedAccountId | table requestingAccountId requestedAccountId firstTime lastTime | outputlookup previously_seen_aws_cross_account_activity

[ESCU - Previously Seen AWS Cross Account Activity - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Cross Account Activity - Update
description = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.creation_date = 2020-08-15
action.escu.modification_date = 2020-08-15
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
action.escu.data_models = ["Authentication"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=AssumeRole by Authentication.vendor_account Authentication.user Authentication.src Authentication.user_role | `drop_dm_object_name(Authentication)` | rex field=user_role "arn:aws:sts:*:(?<dest_account>.*):" | where vendor_account != dest_account | rename vendor_account as requestingAccountId dest_account as requestedAccountId | inputlookup append=t previously_seen_aws_cross_account_activity | stats min(firstTime) as firstTime max(lastTime) as lastTime by requestingAccountId requestedAccountId | outputlookup previously_seen_aws_cross_account_activity

[ESCU - Previously Seen AWS Provisioning Activity Sources]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Provisioning Activity Sources
description = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats count

[ESCU - Previously Seen AWS Regions]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Regions
description = This search looks for CloudTrail events where an AWS instance is started and creates a baseline of most recent time (latest) and the first time (earliest) we've seen this region in our dataset grouped by the value awsRegion for the last 30 days
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where an AWS instance is started and creates a baseline of most recent time (latest) and the first time (earliest) we've seen this region in our dataset grouped by the value awsRegion for the last 30 days
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` StartInstances | stats earliest(_time) as earliest latest(_time) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | stats count

[ESCU - Previously Seen Cloud API Calls Per User Role - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud API Calls Per User Role - Initial
description = This search builds a table of the first and last times seen for every user role and command combination. This is broadly defined as any event that runs or creates something. This table is then cached.
action.escu.creation_date = 2020-09-03
action.escu.modification_date = 2020-09-03
action.escu.analytic_story = ["Suspicious Cloud User Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of the first and last times seen for every user role and command combination. This is broadly defined as any event that runs or creates something. This table is then cached.
action.escu.how_to_implement = You must be ingesting Cloud infrastructure logs from your cloud provider.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.user_type=AssumedRole AND All_Changes.status=success by All_Changes.user, All_Changes.command | `drop_dm_object_name("All_Changes")` | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | table user, command, firstTimeSeen, lastTimeSeen, enough_data | outputlookup previously_seen_cloud_api_calls_per_user_role

[ESCU - Previously Seen Cloud API Calls Per User Role - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud API Calls Per User Role - Update
description = This search updates the table of the first and last times seen for every user role and command combination.
action.escu.creation_date = 2020-09-03
action.escu.modification_date = 2020-09-03
action.escu.analytic_story = ["Suspicious Cloud User Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search updates the table of the first and last times seen for every user role and command combination.
action.escu.how_to_implement = You must be ingesting Cloud infrastructure logs from your cloud provider.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.user_type=AssumedRole AND All_Changes.status=success by All_Changes.user, All_Changes.command | `drop_dm_object_name("All_Changes")` | table user, command, firstTimeSeen, lastTimeSeen | inputlookup previously_seen_cloud_api_calls_per_user_role append=t | stats min(firstTimeSeen) as firstTimeSeen, max(lastTimeSeen) as lastTimeSeen by user, command | where lastTimeSeen > relative_time(now(), `previously_seen_cloud_api_calls_per_user_role_forget_window`) | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | table user, command, firstTimeSeen, lastTimeSeen, enough_data | outputlookup previously_seen_cloud_api_calls_per_user_role

[ESCU - Previously Seen Cloud Compute Creations By User - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Creations By User - Initial
description = This search builds a table of previously seen users that have launched a cloud compute instance.
action.escu.creation_date = 2020-08-15
action.escu.modification_date = 2020-08-15
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 55 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen users that have launched a cloud compute instance.
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the proper TAs installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=created AND All_Changes.object_category=instance by All_Changes.user | `drop_dm_object_name("All_Changes")` | outputlookup previously_seen_cloud_compute_creations_by_user | stats count

[ESCU - Previously Seen Cloud Compute Creations By User - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Creations By User - Update
description = This search builds a table of previously seen users that have launched a cloud compute instance.
action.escu.creation_date = 2020-08-15
action.escu.modification_date = 2020-08-15
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen users that have launched a cloud compute instance.
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the proper TAs installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=created AND All_Changes.object_category=instance by All_Changes.user| `drop_dm_object_name("All_Changes")` | inputlookup append=t previously_seen_cloud_compute_creations_by_user | stats min(firstTimeSeen) as firstTimeSeen max(lastTimeSeen) as lastTimeSeen by user | where lastTimeSeen > relative_time(now(), "-90d@d") | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | outputlookup previously_seen_cloud_compute_creations_by_user

[ESCU - Previously Seen Cloud Compute Images - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Images - Initial
description = This search builds a table of previously seen images used to launch cloud compute instances
action.escu.creation_date = 2020-10-08
action.escu.modification_date = 2020-10-08
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen images used to launch cloud compute instances
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the latest Change Datamodel accelerated
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=created  by All_Changes.Instance_Changes.image_id | `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Instance_Changes")` | where image_id != "unknown" | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | outputlookup previously_seen_cloud_compute_images

[ESCU - Previously Seen Cloud Compute Images - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Images - Update
description = This search builds a table of previously seen images used to launch cloud compute instances
action.escu.creation_date = 2020-08-12
action.escu.modification_date = 2020-08-12
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen images used to launch cloud compute instances
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=created by All_Changes.Instance_Changes.image_id | `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Instance_Changes")` | where image_id != "unknown" | inputlookup append=t previously_seen_cloud_compute_images | stats min(firstTimeSeen) as firstTimeSeen max(lastTimeSeen) as lastTimeSeen by image_id | where lastTimeSeen > relative_time(now(), `previously_seen_cloud_compute_images_forget_window`) | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | outputlookup previously_seen_cloud_compute_images

[ESCU - Previously Seen Cloud Compute Instance Types - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Instance Types - Initial
description = This search builds a table of previously seen cloud compute instance types
action.escu.creation_date = 2020-9-03
action.escu.modification_date = 2020-9-03
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen cloud compute instance types
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=created by All_Changes.Instance_Changes.instance_type | `drop_dm_object_name("All_Changes.Instance_Changes")` | where instance_type != "unknown" | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-14d@d"), 1, 0) | outputlookup previously_seen_cloud_compute_instance_types

[ESCU - Previously Seen Cloud Compute Instance Types - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Compute Instance Types - Update
description = This search builds a table of previously seen cloud compute instance types
action.escu.creation_date = 2020-9-03
action.escu.modification_date = 2020-9-03
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen cloud compute instance types
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=created by All_Changes.Instance_Changes.instance_type | `drop_dm_object_name("All_Changes.Instance_Changes")` | where instance_type != "unknown" | inputlookup append=t previously_seen_cloud_compute_instance_types | stats min(firstTimeSeen) as firstTimeSeen max(lastTimeSeen) as lastTimeSeen by instance_type | where lastTimeSeen > relative_time(now(), `previously_seen_cloud_compute_instance_type_forget_window`) | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-14d@d"), 1, 0) | outputlookup previously_seen_cloud_compute_instance_types

[ESCU - Previously Seen Cloud Instance Modifications By User - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Instance Modifications By User - Initial
description = This search builds a table of previously seen users that have modified a cloud instance.
action.escu.creation_date = 2020-07-29
action.escu.modification_date = 2020-07-29
action.escu.analytic_story = ["Suspicious Cloud Instance Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen users that have modified a cloud instance.
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the latest Change Datamodel accelerated.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=modified All_Changes.change_type=EC2 All_Changes.status=success by All_Changes.user | `drop_dm_object_name("All_Changes")` | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | outputlookup previously_seen_cloud_instance_modifications_by_user

[ESCU - Previously Seen Cloud Instance Modifications By User - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Instance Modifications By User - Update
description = This search updates a table of previously seen Cloud Instance modifications that have been made by a user
action.escu.creation_date = 2020-07-29
action.escu.modification_date = 2020-07-29
action.escu.analytic_story = ["Suspicious Cloud Instance Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search updates a table of previously seen Cloud Instance modifications that have been made by a user
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=modified All_Changes.change_type=EC2 All_Changes.status=success by All_Changes.user | `drop_dm_object_name("All_Changes")` | inputlookup append=t previously_seen_cloud_instance_modifications_by_user | stats min(firstTimeSeen) as firstTimeSeen max(lastTimeSeen) as lastTimeSeen by user | where lastTimeSeen > relative_time(now(), `previously_seen_cloud_compute_images_forget_window`) | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | outputlookup previously_seen_cloud_instance_modifications_by_user

[ESCU - Previously Seen Cloud Provisioning Activity Sources - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Provisioning Activity Sources - Initial
description = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something. This table is then cached.
action.escu.creation_date = 2020-08-19
action.escu.modification_date = 2020-08-19
action.escu.analytic_story = ["Suspicious Cloud Provisioning Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something. This table is then cached.
action.escu.how_to_implement = You must be ingesting Cloud infrastructure logs from your cloud provider.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src | `drop_dm_object_name("All_Changes")` | iplocation src | where isnotnull(Country) | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | table src, City, Country, Region, firstTimeSeen, lastTimeSeen, enough_data | outputlookup previously_seen_cloud_provisioning_activity_sources

[ESCU - Previously Seen Cloud Provisioning Activity Sources - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Provisioning Activity Sources - Update
description = This returns the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity within the last day. Cloud provisioning is broadly defined as any event that runs or creates something.  It then updates this information with historical data and filters out locations that have not been seen within the specified time window. This updated table is then cached.
action.escu.creation_date = 2020-08-20
action.escu.modification_date = 2020-08-20
action.escu.analytic_story = ["Suspicious Cloud Provisioning Activities"]
action.escu.data_models = ["Change"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This returns the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity within the last day. Cloud provisioning is broadly defined as any event that runs or creates something.  It then updates this information with historical data and filters out locations that have not been seen within the specified time window. This updated table is then cached.
action.escu.how_to_implement = You must be ingesting Cloud infrastructure logs from your cloud provider.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src | `drop_dm_object_name("All_Changes")` | iplocation src | where isnotnull(Country) | table src, firstTimeSeen, lastTimeSeen, City, Country, Region | inputlookup previously_seen_cloud_provisioning_activity_sources append=t | stats min(firstTimeSeen) as firstTimeSeen, max(lastTimeSeen) as lastTimeSeen by src, City, Country, Region | where lastTimeSeen > relative_time(now(), `previously_seen_cloud_provisioning_activity_forget_window`) | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-7d@d"), 1, 0) | table src, City, Country, Region, firstTimeSeen, lastTimeSeen, enough_data | outputlookup previously_seen_cloud_provisioning_activity_sources

[ESCU - Previously Seen Cloud Regions - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Regions - Initial
description = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
action.escu.creation_date = 2020-09-02
action.escu.modification_date = 2020-09-02
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=created by All_Changes.vendor_region | `drop_dm_object_name("All_Changes")` | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-14d@d"), 1, 0) | outputlookup previously_seen_cloud_regions

[ESCU - Previously Seen Cloud Regions - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Cloud Regions - Update
description = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
action.escu.creation_date = 2020-09-02
action.escu.modification_date = 2020-09-02
action.escu.analytic_story = ["Cloud Cryptomining"]
action.escu.data_models = ["Change"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
action.escu.how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen from datamodel=Change where All_Changes.action=created by All_Changes.vendor_region | `drop_dm_object_name("All_Changes")` | inputlookup append=t previously_seen_cloud_regions | stats min(firstTimeSeen) as firstTimeSeen max(lastTimeSeen) as lastTimeSeen by vendor_region | where lastTimeSeen > relative_time(now(), `previously_seen_cloud_region_forget_window`) | eventstats min(firstTimeSeen) as globalFirstTime | eval enough_data = if(globalFirstTime <= relative_time(now(), "-14d@d"), 1, 0) | outputlookup previously_seen_cloud_regions | stats count

[ESCU - Previously Seen EC2 AMIs]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 AMIs
description = This search builds a table of previously seen AMIs used to launch EC2 instances
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS Cryptomining"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen AMIs used to launch EC2 instances
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success | rename requestParameters.instancesSet.items{}.imageId as amiID | stats earliest(_time) as firstTime latest(_time) as lastTime by amiID | outputlookup previously_seen_ec2_amis.csv | stats count

[ESCU - Previously Seen EC2 Instance Types]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Instance Types
description = This search builds a table of previously seen EC2 instance types
action.escu.creation_date = 2018-03-08
action.escu.modification_date = 2018-03-08
action.escu.analytic_story = ["AWS Cryptomining"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen EC2 instance types
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success | rename requestParameters.instanceType as instanceType | fillnull value="m1.small" instanceType | stats earliest(_time) as earliest latest(_time) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | stats count

[ESCU - Previously Seen EC2 Launches By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Launches By User
description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-15
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
disabled = true
is_visible = false
search = `cloudtrail` eventName=RunInstances errorCode=success | rename userIdentity.arn as arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | stats count

[ESCU - Previously Seen EC2 Modifications By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Modifications By User
description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.creation_date = 2018-04-05
action.escu.modification_date = 2018-04-05
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.
disabled = true
is_visible = false
search = `cloudtrail` `ec2_modification_api_calls` errorCode=success | spath output=arn userIdentity.arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user | stats count

[ESCU - Previously Seen Running Windows Services - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Running Windows Services - Initial
description = This collects the services that have been started across your entire enterprise.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.analytic_story = ["Orangeworm Attack Group", "Windows Service Abuse", "NOBELIUM Group"]
action.escu.data_models = []
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This collects the services that have been started across your entire enterprise.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs for it to execute successfully. Please ensure that the Splunk Add-on for Microsoft Windows is version 8.0.0 or above.
disabled = true
is_visible = false
search = `wineventlog_system` EventCode=7036 | rex field=Message "The (?<service>[-\(\)\s\w]+) service entered the (?<state>\w+) state" | where state="running" | stats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen by service | outputlookup previously_seen_running_windows_services

[ESCU - Previously Seen Running Windows Services - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Running Windows Services - Update
description = This search returns the first and last time a Windows service was seen across your enterprise within the last hour. It then updates this information with historical data and filters out Windows services pairs that have not been seen within the specified time window. This updated table is then cached.
action.escu.creation_date = 2020-06-23
action.escu.modification_date = 2020-06-23
action.escu.analytic_story = ["Orangeworm Attack Group", "Windows Service Abuse", "NOBELIUM Group"]
action.escu.data_models = []
cron_schedule = 55 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search returns the first and last time a Windows service was seen across your enterprise within the last hour. It then updates this information with historical data and filters out Windows services pairs that have not been seen within the specified time window. This updated table is then cached.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs for it to execute successfully. Please ensure that the Splunk Add-on for Microsoft Windows is version 8.0.0 or above.
disabled = true
is_visible = false
search = `wineventlog_system` EventCode=7036 | rex field=Message "The (?<service>[-\(\)\s\w]+) service entered the (?<state>\w+) state" | where state="running" | stats earliest(_time) as firstTimeSeen, latest(_time) as lastTimeSeen by service | inputlookup previously_seen_running_windows_services append=t | stats min(firstTimeSeen) as firstTimeSeen, max(lastTimeSeen) as lastTimeSeen by service | where lastTimeSeen > relative_time(now(), "`previously_seen_windows_service_forget_window`") | outputlookup previously_seen_running_windows_services

[ESCU - Previously Seen Users In CloudTrail - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Users In CloudTrail - Update
description = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by user, within the last hour.
action.escu.creation_date = 2020-05-28
action.escu.modification_date = 2020-05-28
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
action.escu.data_models = ["Authentication"]
cron_schedule = 10 0 * * *
enableSched = 1
dispatch.earliest_time = -1450m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by user, within the last hour.
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_users_console_logins`, which is a lookup file created by this support search.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | rename Authentication.user as user Authentication.src as src | table user src City Region Country firstTime lastTime | inputlookup append=t previously_seen_users_console_logins | stats min(firstTime) as firstTime max(lastTime) as lastTime by user src City Region Country | outputlookup previously_seen_users_console_logins

[ESCU - Previously Seen Users in CloudTrail - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Users in CloudTrail - Initial
description = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by username, within the last 30 days.
action.escu.creation_date = 2020-05-28
action.escu.modification_date = 2020-05-28
action.escu.analytic_story = ["Suspicious Cloud Authentication Activities"]
action.escu.data_models = ["Authentication"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by username, within the last 30 days.
action.escu.how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_users_console_logins`, which is a lookup file created by this support search.
disabled = true
is_visible = false
search = | tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | rename Authentication.user as user Authentication.src as src | table user src City Region Country firstTime lastTime | outputlookup previously_seen_users_console_logins | stats count

[ESCU - Previously Seen Zoom Child Processes - Initial]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Zoom Child Processes - Initial
description = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS). This table is then cached.
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.analytic_story = ["Suspicious Zoom Child Processes"]
action.escu.data_models = ["Endpoint"]
cron_schedule = 0 1 1 1,4,7,10 *
enableSched = 1
dispatch.earliest_time = -90d@d
dispatch.latest_time = -1d@d
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS). This table is then cached.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTimeSeen max(_time) as lastTimeSeen from datamodel=Endpoint.Processes where (Processes.parent_process_name=zoom.exe OR Processes.parent_process_name=zoom.us) by Processes.process_name Processes.dest| `drop_dm_object_name(Processes)` | table dest, process_name, firstTimeSeen, lastTimeSeen | outputlookup zoom_first_time_child_process

[ESCU - Previously Seen Zoom Child Processes - Update]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Zoom Child Processes - Update
description = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS) within the last hour. It then updates this information with historical data and filters out proces_name and endpoint pairs that have not been seen within the specified time window. This updated table is outputed to disk.
action.escu.creation_date = 2020-05-20
action.escu.modification_date = 2020-05-20
action.escu.analytic_story = ["Suspicious Zoom Child Processes"]
action.escu.data_models = ["Endpoint"]
cron_schedule = 55 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS) within the last hour. It then updates this information with historical data and filters out proces_name and endpoint pairs that have not been seen within the specified time window. This updated table is outputed to disk.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTimeSeen max(_time) as lastTimeSeen from datamodel=Endpoint.Processes where (Processes.parent_process_name=zoom.exe OR Processes.parent_process_name=zoom.us) by Processes.process_name Processes.dest| `drop_dm_object_name(Processes)` | table firstTimeSeen, lastTimeSeen, process_name, dest | inputlookup zoom_first_time_child_process append=t | stats min(firstTimeSeen) as firstTimeSeen max(lastTimeSeen) as lastTimeSeen by process_name, dest | where lastTimeSeen > relative_time(now(), "`previously_seen_zoom_child_processes_forget_window`") | outputlookup zoom_first_time_child_process

[ESCU - Previously seen API call per user roles in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen API call per user roles in CloudTrail
description = This search looks for successful API calls made by different user roles, then creates a baseline of the earliest and latest times we have encountered this user role. It also returns the name of the API call in our dataset--grouped by user role and name of the API call--that occurred within the last 30 days. In this support search, we are only looking for events where the user identity is Assumed Role.
action.escu.creation_date = 2018-04-16
action.escu.modification_date = 2018-04-16
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for successful API calls made by different user roles, then creates a baseline of the earliest and latest times we have encountered this user role. It also returns the name of the API call in our dataset--grouped by user role and name of the API call--that occurred within the last 30 days. In this support search, we are only looking for events where the user identity is Assumed Role.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user role entries in `previously_seen_api_calls_from_user_roles.csv`, which is a lookup file created as a result of running this support search.
disabled = true
is_visible = false
search = `cloudtrail` eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles | stats count

[ESCU - Previously seen S3 bucket access by remote IP]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen S3 bucket access by remote IP
description = This search looks for successful access to S3 buckets from remote IP addresses, then creates a baseline of the earliest and latest times we have encountered this remote IP within the last 30 days. In this support search, we are only looking for S3 access events where the HTTP response code from AWS is "200"
action.escu.creation_date = 2018-06-28
action.escu.modification_date = 2018-06-28
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for successful access to S3 buckets from remote IP addresses, then creates a baseline of the earliest and latest times we have encountered this remote IP within the last 30 days. In this support search, we are only looking for S3 access events where the HTTP response code from AWS is "200"
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access-logs inputs. You must validate the remote IP and bucket name entries in `previously_seen_S3_access_from_remote_ip.csv`, which is a lookup file created as a result of running this support search.
disabled = true
is_visible = false
search = `aws_s3_accesslogs` http_status=200  | stats  earliest(_time) as earliest latest(_time) as latest by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip | stats count

[ESCU - Previously seen command line arguments]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen command line arguments
description = This search looks for command-line arguments where `cmd.exe /c` is used to execute a program, then creates a baseline of the earliest and latest times we have encountered this command-line argument in our dataset within the last 30 days.
action.escu.creation_date = 2019-03-01
action.escu.modification_date = 2019-03-01
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Hidden Cobra Malware", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity"]
action.escu.data_models = ["Endpoint"]
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for command-line arguments where `cmd.exe /c` is used to execute a program, then creates a baseline of the earliest and latest times we have encountered this command-line argument in our dataset within the last 30 days.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe AND Processes.process="* /c *" by Processes.process | `drop_dm_object_name(Processes)`

[ESCU - Previously seen users in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen users in CloudTrail
description = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last 30 days. NOTE - This baseline search is deprecated and has been updated to use the Authentication Datamodel
action.escu.creation_date = 2018-04-30
action.escu.modification_date = 2018-04-30
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last 30 days. NOTE - This baseline search is deprecated and has been updated to use the Authentication Datamodel
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins_cloudtrail`, which is a lookup file created as a result of running this support search.
disabled = true
is_visible = false
search = `cloudtrail` eventName=ConsoleLogin | rename userIdentity.arn as user | iplocation src | eval City=if(City LIKE "",src,City),Region=if(Region LIKE "",src,Region) | stats earliest(_time) as firstTime latest(_time) as lastTime by user src City Region Country | outputlookup previously_seen_users_console_logins_cloudtrail | stats count

[ESCU - Systems Ready for Spectre-Meltdown Windows Patch]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Systems Ready for Spectre-Meltdown Windows Patch
description = Some AV applications can cause the Spectre/Meltdown patch for Windows not to install successfully. This registry key is supposed to be created by the AV engine when it has been patched to be able to handle the Windows patch. If this key has been written, the system can then be patched for Spectre and Meltdown.
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = Some AV applications can cause the Spectre/Meltdown patch for Windows not to install successfully. This registry key is supposed to be created by the AV engine when it has been patched to be able to handle the Windows patch. If this key has been written, the system can then be patched for Spectre and Meltdown.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="HKLM\Software\Microsoft\Windows\CurrentVersion\QualityCompat*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("All_Changes")`

[ESCU - Update previously seen users in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Update previously seen users in CloudTrail
description = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last hour. NOTE - This baseline search is deprecated and has been updated to use the Authentication Datamodel
action.escu.creation_date = 2018-04-30
action.escu.modification_date = 2018-04-30
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last hour. NOTE - This baseline search is deprecated and has been updated to use the Authentication Datamodel
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins_cloudtrail`, which is a lookup file created as a result of running this support search.
disabled = true
is_visible = false
search = `cloudtrail` eventName=ConsoleLogin | rename userIdentity.arn as user | iplocation src | eval City=if(City LIKE "",src,City),Region=if(Region LIKE "",src,Region) | stats earliest(_time) AS firstTime latest(_time) AS lastTime by user src City Region Country | inputlookup append=t previously_seen_users_console_logins_cloudtrail | stats min(firstTime) as firstTime max(lastTime) as lastTime by user src City Region Country | outputlookup previously_seen_users_console_logins_cloudtrail

[ESCU - Windows Updates Install Failures]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Windows Updates Install Failures
description = This search is intended to give you a feel for how often Windows updates fail to install in your environment. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.creation_date = 2017-09-14
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = []
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is intended to give you a feel for how often Windows updates fail to install in your environment. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=failure by _time span=1d

[ESCU - Windows Updates Install Successes]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Windows Updates Install Successes
description = This search is intended to give you a feel for how often successful Windows updates are applied in your environments. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.creation_date = 2017-09-14
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = []
action.escu.data_models = []
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
schedule_window = auto
action.escu.providing_technologies = []
action.escu.eli5 = This search is intended to give you a feel for how often successful Windows updates are applied in your environments. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
disabled = true
is_visible = false
search = | tstats `security_content_summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=installed by _time span=1d



### ESCU RESPONSE TASKS ###

[ESCU - AWS Investigate Security Hub alerts by dest - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate Security Hub alerts by dest - Response Task
description = This search retrieves the all the alerts created by AWS Security Hub for a specific dest(instance_id).
action.escu.creation_date = 2020-06-08
action.escu.modification_date = 2020-06-08
action.escu.analytic_story = ["Cloud Compute Instance", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves the all the alerts created by AWS Security Hub for a specific dest(instance_id).
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="aws:securityhub:firehose" "findings{}.Resources{}.Type"=AWSEC2Instance | rex field=findings{}.Resources{}.Id .*instance/(?<instance>.*)| rename instance as dest| search dest = $dest$ |rename findings{}.* as * | rename Remediation.Recommendation.Text as Remediation |  table dest Title ProductArn Description FirstObservedAt RecordState Remediation

[ESCU - AWS Investigate User Activities By ARN - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By ARN - Response Task
description = This search lists all the logged CloudTrail activities by a specific user ARN and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and all the user's identity information.
action.escu.creation_date = 2019-04-30
action.escu.modification_date = 2019-04-30
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "Cloud Cryptomining", "Command and Control", "Suspicious AWS EC2 Activities", "Suspicious AWS Login Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Unusual AWS EC2 Modifications", "Suspicious Cloud User Activities", "AWS Suspicious Provisioning Activities", "Suspicious Cloud Instance Activities", "AWS Security Hub Alerts"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the logged CloudTrail activities by a specific user ARN and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and all the user's identity information.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | search user=$user$| table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType

[ESCU - AWS Investigate User Activities By AccessKeyId - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By AccessKeyId - Response Task
description = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific credentials.
action.escu.creation_date = 2018-06-08
action.escu.modification_date = 2018-06-08
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific credentials.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | rename userIdentity.accessKeyId as accessKeyId| search accessKeyId=$accessKeyId$ | spath output=user path=userIdentity.arn  | rename sourceIPAddress as src_ip | table _time, user, src_ip, awsRegion, eventName, errorCode, errorMessage

[ESCU - AWS Network ACL Details from ID - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Network ACL Details from ID - Response Task
description = This search queries AWS description logs and returns all the information about a specific network ACL via network ACL ID
action.escu.creation_date = 2017-01-22
action.escu.modification_date = 2017-01-22
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries AWS description logs and returns all the information about a specific network ACL via network ACL ID
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:description| rename id as networkAclId | search  networkAclId=$networkAclId$ | table id account_id vpc_id network_acl_entries{}.*

[ESCU - AWS Network Interface details via resourceId - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Network Interface details via resourceId - Response Task
description = This search queries AWS configuration logs and returns the information about a specific network interface via network interface ID. The information will include the ARN of the network interface, its relationships with other AWS resources, the public and the private IP associated with the network interface.
action.escu.creation_date = 2018-05-07
action.escu.modification_date = 2018-05-07
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries AWS configuration logs and returns the information about a specific network interface via network interface ID. The information will include the ARN of the network interface, its relationships with other AWS resources, the public and the private IP associated with the network interface.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:config resourceId=$resourceId$ | table _time ARN relationships{}.resourceType relationships{}.name relationships{}.resourceId  configuration.privateIpAddresses{}.privateIpAddress configuration.privateIpAddresses{}.association.publicIp

[ESCU - AWS S3 Bucket details via bucketName - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS S3 Bucket details via bucketName - Response Task
description = This search queries AWS configuration logs and returns the information about a specific S3 bucket. The information returned includes the time the S3 bucket was created, the resource ID, the region it belongs to, the value of action performed, AWS account ID, and configuration values of the access-control lists associated with the bucket.
action.escu.creation_date = 2018-06-26
action.escu.modification_date = 2018-06-26
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries AWS configuration logs and returns the information about a specific S3 bucket. The information returned includes the time the S3 bucket was created, the resource ID, the region it belongs to, the value of action performed, AWS account ID, and configuration values of the access-control lists associated with the bucket.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:config | rename resourceId as bucketName |search bucketName=$bucketName$ | table resourceCreationTime bucketName vendor_region action aws_account_id supplementaryConfiguration.AccessControlList

[ESCU - All backup logs for host - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - All backup logs for host - Response Task
description = Retrieve the backup logs for the last 2 weeks for a specific host in order to investigate why backups are not completing successfully.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = Retrieve the backup logs for the last 2 weeks for a specific host in order to investigate why backups are not completing successfully.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="netbackup_logs" dest=$dest$

[ESCU - Amazon EKS Kubernetes activity by src ip - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Amazon EKS Kubernetes activity by src ip - Response Task
description = This search provides investigation data about requests via user agent, authentication request URI, verb and cluster name data against Kubernetes cluster from a specific IP address
action.escu.creation_date = 2020-04-13
action.escu.modification_date = 2020-04-13
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search provides investigation data about requests via user agent, authentication request URI, verb and cluster name data against Kubernetes cluster from a specific IP address
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="aws:cloudwatchlogs:eks" |rename sourceIPs{} as src_ip |search src_ip=$src_ip$ | stats count min(_time) as firstTime max(_time) as lastTime values(user.username) values(requestURI) values(verb) values(userAgent) by source annotations.authorization.k8s.io/decision src_ip

[ESCU - GCP Kubernetes activity by src ip - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - GCP Kubernetes activity by src ip - Response Task
description = This search provides investigation data about requests via user agent, authentication request URI, resource path and cluster name data against Kubernetes cluster from a specific IP address
action.escu.creation_date = 2020-04-13
action.escu.modification_date = 2020-04-13
action.escu.analytic_story = ["Kubernetes Scanning Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search provides investigation data about requests via user agent, authentication request URI, resource path and cluster name data against Kubernetes cluster from a specific IP address
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="google:gcp:pubsub:message" | rename data.protoPayload.requestMetadata.callerIp as src_ip | search src_ip =$src_ip$ | stats count min(_time) as firstTime max(_time) as lastTime values(data.protoPayload.methodName) as method_names values(data.protoPayload.resourceName) as resource_name values(data.protoPayload.requestMetadata.callerSuppliedUserAgent) as http_user_agent values(data.protoPayload.authenticationInfo.principalEmail) as user values(data.protoPayload.status.message) by src_ip data.resource.labels.cluster_name data.resource.type

[ESCU - Get All AWS Activity From City - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From City - Response Task
description = This search retrieves all the activity from a specific city and will create a table containing the time, city, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves all the activity from a specific city and will create a table containing the time, city, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search City=$City$ | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, City, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From Country - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From Country - Response Task
description = This search retrieves all the activity from a specific country and will create a table containing the time, country, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves all the activity from a specific country and will create a table containing the time, country, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Country=$Country$ | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Country, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From IP Address - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From IP Address - Response Task
description = This search retrieves all the activity from a specific IP address and will create a table containing the time, ARN, username, the type of user, the IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Network ACL Activity", "AWS Suspicious Provisioning Activities", "Command and Control", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Cloud Instance Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves all the activity from a specific IP address and will create a table containing the time, ARN, username, the type of user, the IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search src_ip=$src_ip$ | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From Region - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From Region - Response Task
description = This search retrieves all the activity from a specific geographic region and will create a table containing the time, geographic region, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search retrieves all the activity from a specific geographic region and will create a table containing the time, geographic region, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Region=$Region$ | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Region, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get Backup Logs For Endpoint - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Backup Logs For Endpoint - Response Task
description = This search will tell you the backup status from your netbackup_logs of a specific endpoint for the last week.
action.escu.creation_date = 2017-09-14
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search will tell you the backup status from your netbackup_logs of a specific endpoint for the last week.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="netbackup_logs" COMPUTERNAME=$dest$ | rename COMPUTERNAME as dest, MESSAGE as signature | table _time, dest, signature

[ESCU - Get Certificate logs for a domain - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Certificate logs for a domain - Response Task
description = This search queries the Certificates datamodel and give you all the information for a specific domain. Please note that the certificates issued by "Let's Encrypt" are widely used by attackers.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.analytic_story = ["Common Phishing Frameworks"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the Certificates datamodel and give you all the information for a specific domain. Please note that the certificates issued by "Let's Encrypt" are widely used by attackers.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Certificates.All_Certificates where All_Certificates.SSL.ssl_subject_common_name=*$domain$  by All_Certificates.dest All_Certificates.src All_Certificates.SSL.ssl_issuer_common_name All_Certificates.SSL.ssl_subject_common_name All_Certificates.SSL.ssl_hash | `drop_dm_object_name(All_Certificates)` | `drop_dm_object_name(SSL)` | rename ssl_subject_common_name as domain | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get DNS Server History for a host - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get DNS Server History for a host - Response Task
description = While investigating any detections it is important to understand which and how many DNS servers a host has connected to in the past. This search uses data that is tagged as DNS and gives you a count and list of DNS servers that a particular host has connected to the previous 24 hours.
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "DNS Hijacking", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Host Redirection", "Prohibited Traffic Allowed or Protocol Mismatch", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = While investigating any detections it is important to understand which and how many DNS servers a host has connected to in the past. This search uses data that is tagged as DNS and gives you a count and list of DNS servers that a particular host has connected to the previous 24 hours.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search tag=dns src_ip=$src_ip$ dest_port=53 | streamstats time_window=1d count values(dest_ip) as dcip by src_ip | table date_mday src_ip dcip count | sort -count

[ESCU - Get DNS traffic ratio - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get DNS traffic ratio - Response Task
description = This search calculates the ratio of DNS traffic originating and coming from a host to a list of DNS servers over the last 24 hours. A high value of this ratio could be very useful to quickly understand if a src_ip (host) is sending a high volume of data out via port 53, could be an indicator of data exfiltration via DNS.  
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search calculates the ratio of DNS traffic originating and coming from a host to a list of DNS servers over the last 24 hours. A high value of this ratio could be very useful to quickly understand if a src_ip (host) is sending a high volume of data out via port 53, could be an indicator of data exfiltration via DNS.  
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats allow_old_summaries=true sum(All_Traffic.bytes_out) as "bytes_out" sum(All_Traffic.bytes_in) as "bytes_in" from datamodel=Network_Traffic where nodename=All_Traffic All_Traffic.dest_port=53 by All_Traffic.src All_Traffic.dest| `drop_dm_object_name(All_Traffic)` | rename src as src_ip | rename dest as dest_ip | search src_ip=$src_ip$ | search dest_ip = $dest_ip | eval ratio = (bytes_out/bytes_in) | table ratio

[ESCU - Get EC2 Instance Details by instanceId - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get EC2 Instance Details by instanceId - Response Task
description = This search queries AWS description logs and returns all the information about a specific instance via the instanceId field
action.escu.creation_date = 2018-02-12
action.escu.modification_date = 2018-02-12
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "Unusual AWS EC2 Modifications", "AWS Security Hub Alerts"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries AWS description logs and returns all the information about a specific instance via the instanceId field
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype="aws:description" source="*:ec2_instances"| dedup id sortby -_time |rename id as instanceId|  search instanceId=$instanceId$ | spath output=tags path=tags | eval tags=mvzip(key,value," = "), ip_address=if((ip_address == "null"),private_ip_address,ip_address) | table id, tags.Name, aws_account_id, placement, instance_type, key_name, ip_address, launch_time, state, vpc_id, subnet_id, tags | rename aws_account_id as "Account ID", id as ID, instance_type as Type, ip_address as "IP Address", key_name as "Key Pair", launch_time as "Launch Time", placement as "Availability Zone", state as State, subnet_id as Subnet, "tags.Name" as Name, vpc_id as VPC

[ESCU - Get EC2 Launch Details - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get EC2 Launch Details - Response Task
description = This search returns some of the launch details for a EC2 instance.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "AWS Security Hub Alerts"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns some of the launch details for a EC2 instance.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail dest=$dest$ |rename userIdentity.arn as arn, responseElements.instancesSet.items{}.instanceId as dest, responseElements.instancesSet.items{}.privateIpAddress as privateIpAddress, responseElements.instancesSet.items{}.imageId as amiID, responseElements.instancesSet.items{}.architecture as architecture, responseElements.instancesSet.items{}.keyName as keyName | table arn, awsRegion, dest, architecture, privateIpAddress, amiID, keyName

[ESCU - Get Email Info - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Email Info - Response Task
description = This search returns all the information Splunk might have collected a specific email message over the last 2 hours.
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all the information Splunk might have collected a specific email message over the last 2 hours.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search message_id=$message_id$

[ESCU - Get Emails From Specific Sender - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Emails From Specific Sender - Response Task
description = This search returns all the emails from a specific sender over the last 24 and next hours.
action.escu.creation_date = 2017-11-09
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Suspicious Emails", "Web Fraud Detection"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all the emails from a specific sender over the last 24 and next hours.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search src_user=$src_user$

[ESCU - Get First Occurrence and Last Occurrence of a MAC Address - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get First Occurrence and Last Occurrence of a MAC Address - Response Task
description = This search allows you to gather more context around a notable which has detected a new device connecting to your network. Use this search to determine the first and last occurrences of the suspicious device attempting to connect with your network.
action.escu.creation_date = 2017-09-13
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Asset Tracking"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Network_Sessions"]
action.escu.eli5 = This search allows you to gather more context around a notable which has detected a new device connecting to your network. Use this search to determine the first and last occurrences of the suspicious device attempting to connect with your network.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST All_Sessions.All_Sessions.src_mac= $src_mac$ by All_Sessions.src_ip All_Sessions.user | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)`

[ESCU - Get History Of Email Sources - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get History Of Email Sources - Response Task
description = This search returns a list of all email sources seen in the 48 hours prior to the notable event to 24 hours after, and the number of emails from each source.
action.escu.creation_date = 2019-02-21
action.escu.modification_date = 2019-02-21
action.escu.analytic_story = ["Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Lateral Movement", "Malicious PowerShell", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Email"]
action.escu.eli5 = This search returns a list of all email sources seen in the 48 hours prior to the notable event to 24 hours after, and the number of emails from each source.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = |tstats `security_content_summariesonly` values(All_Email.dest) as dest values(All_Email.recipient) as recepient  min(_time) as firstTime max(_time) as lastTime count from datamodel=Email.All_Email by All_Email.src |`drop_dm_object_name(All_Email)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search src=$src$

[ESCU - Get Logon Rights Modifications For Endpoint - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For Endpoint - Response Task
description = This search allows you to retrieve any modifications to logon rights associated with a specific host.
action.escu.creation_date = 2017-09-12
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search allows you to retrieve any modifications to logon rights associated with a specific host.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search eventtype=wineventlog_security (signature_id=4718 OR signature_id=4717) dest=$dest$ | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Get Logon Rights Modifications For User - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For User - Response Task
description = This search allows you to retrieve any modifications to logon rights for a specific user account.
action.escu.creation_date = 2019-02-27
action.escu.modification_date = 2019-02-27
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search allows you to retrieve any modifications to logon rights for a specific user account.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search eventtype=wineventlog_security (signature_id=4718 OR signature_id=4717) user=$user$ | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Get Notable History - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Notable History - Response Task
description = This search queries the notable index and returns all the Notable Events for the particular destination host, giving the analyst an overview of the incidents that may have occurred with the host under investigation.
action.escu.creation_date = 2017-09-20
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cross Account Activity", "AWS Cryptomining", "AWS Network ACL Activity", "AWS User Monitoring", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "Cloud Cryptomining", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Kubernetes Scanning Activity", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router and Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Cloud Authentication Activities", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual AWS EC2 Modifications", "Unusual Processes", "Use of Cleartext Protocols", "Web Fraud Detection", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse", "Data Exfiltration", "F5 TMUI RCE CVE-2020-5902", "Detect Zerologon Attack", "GCP Cross Account Activity", "Kubernetes Sensitive Object Access Activity", "Kubernetes Sensitive Role Activity", "Ransomware Cloud", "Ryuk Ransomware", "Suspicious Cloud Provisioning Activities", "Suspicious GCP Storage Activities", "Windows DNS SIGRed CVE-2020-1350"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the notable index and returns all the Notable Events for the particular destination host, giving the analyst an overview of the incidents that may have occurred with the host under investigation.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search `notable` | search dest=$dest$ | table _time, dest, rule_name, owner, priority, severity, status_description

[ESCU - Get Outbound Emails to Hidden Cobra Threat Actors - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Outbound Emails to Hidden Cobra Threat Actors - Response Task
description = This search returns the information of the users that sent emails to the accounts controlled by the Hidden Cobra Threat Actors: specifically to `misswang8107@gmail.com`, and from `redhat@gmail.com`.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-06-14
action.escu.analytic_story = ["Hidden Cobra Malware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns the information of the users that sent emails to the accounts controlled by the Hidden Cobra Threat Actors: specifically to `misswang8107@gmail.com`, and from `redhat@gmail.com`.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search recipient=misswang8107@gmail.com OR src_user=redhat@gmail.com | stats count earliest(_time) as firstTime, latest(_time) as lastTime values(dest) values(src) by src_user recipient | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Parent Process Info - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Parent Process Info - Response Task
description = This search queries the Endpoint data model to give you details about the parent process of a process running on a host which is under investigation. Enter the values of the process name in question and the dest
action.escu.creation_date = 2019-02-28
action.escu.modification_date = 2019-02-28
action.escu.analytic_story = ["Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Phishing Payloads", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the Endpoint data model to give you details about the parent process of a process running on a host which is under investigation. Enter the values of the process name in question and the dest
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.parent_process_name Processes.process_name Processes.dest | `drop_dm_object_name("Processes")` | search  parent_process_name= $parent_process_name$ |search dest = $dest$ | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Process File Activity - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process File Activity - Response Task
description = This search returns the file activity for a specific process on a specific endpoint
action.escu.creation_date = 2019-11-06
action.escu.modification_date = 2019-11-06
action.escu.analytic_story = ["DHS Report TA18-074A", "Suspicious Zoom Child Processes"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns the file activity for a specific process on a specific endpoint
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Filesystem.file_name) as file_name values(Filesystem.dest) as dest, values(Filesystem.process_name) as process_name from datamodel=Endpoint.Filesystem by Filesystem.dest Filesystem.process_name Filesystem.file_path, Filesystem.action, _time | `drop_dm_object_name(Filesystem)`  | search dest=$dest$  | search process_name=$process_name$ | table _time, process_name, dest, action, file_name, file_path

[ESCU - Get Process Info - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Info - Response Task
description = This search queries the Endpoint data model to give you details about the process running on a host which is under investigation. To gather the process info, enter the values for the process name in question and the destination IP address.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Collection and Staging", "Command and Control", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries the Endpoint data model to give you details about the process running on a host which is under investigation. To gather the process info, enter the values for the process name in question and the destination IP address.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.parent_process_name Processes.process_name Processes.dest | `drop_dm_object_name("Processes")` | search  process_name= $process_name$ | search dest = $dest$ | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`

[ESCU - Get Process Information For Port Activity - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Information For Port Activity - Response Task
description = This search will return information about the process associated with observed network traffic to a specific destination port from a specific host.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "DHS Report TA18-074A", "Emotet Malware  DHS Report TA18-201A ", "Hidden Cobra Malware", "Lateral Movement", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious AWS Traffic", "Use of Cleartext Protocols"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search will return information about the process associated with observed network traffic to a specific destination port from a specific host.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.process_name Processes.user Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search dest=$dest$ | join dest type=inner [| tstats `security_content_summariesonly` count from datamodel=Endpoint.Ports by Ports.process_id Ports.src Ports.dest_port | `drop_dm_object_name(Ports)` | search dest_port=$dest_port$ | rename src as dest]

[ESCU - Get Process Responsible For The DNS Traffic - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Responsible For The DNS Traffic - Response Task
description = While investigating, an analyst will want to know what process and parent_process is responsible for generating suspicious DNS traffic. Use the following search and enter the value of `dest` in the search to get specific details on the process responsible for creating the DNS traffic.
action.escu.creation_date = 2019-04-01
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["AWS Network ACL Activity", "Brand Monitoring", "Command and Control", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Suspicious AWS Traffic", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = While investigating, an analyst will want to know what process and parent_process is responsible for generating suspicious DNS traffic. Use the following search and enter the value of `dest` in the search to get specific details on the process responsible for creating the DNS traffic.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.parent_process Processes.process_name Processes.user Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | search dest = $dest$ | join dest type=inner [| tstats `security_content_summariesonly` count from datamodel=Endpoint.Ports where Ports.dest_port=53 by Ports.process_id Ports.src | `drop_dm_object_name(Ports)` | rename src as dest]

[ESCU - Get Sysmon WMI Activity for Host - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Sysmon WMI Activity for Host - Response Task
description = This search queries Sysmon WMI events for the host of interest.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.analytic_story = ["Ransomware", "Suspicious WMI Use"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search queries Sysmon WMI events for the host of interest.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" EventCode>18 EventCode<22 | rename host as dest | search dest=$dest$| table _time, dest, user, Name, Operation, EventType, Type, Query, Consumer, Filter

[ESCU - Get Web Session Information via session id - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Web Session Information via session id - Response Task
description = This search helps an analyst investigate a notable event to find out more about a specific web session. The search looks for a specific web session ID in the HTTP web traffic and outputs the URL and user agents, grouped by source IP address and HTTP status code.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.analytic_story = ["Web Fraud Detection"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search helps an analyst investigate a notable event to find out more about a specific web session. The search looks for a specific web session ID in the HTTP web traffic and outputs the URL and user agents, grouped by source IP address and HTTP status code.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=stream:http session_id  = $session_id$ | stats values(url) values(http_user_agent) by src_ip status

[ESCU - Investigate AWS User Activities by user field - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS User Activities by user field - Response Task
description = This search lists all the logged CloudTrail activities by a specific user and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and the user's identity information.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS User Monitoring", "Suspicious Cloud Authentication Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the logged CloudTrail activities by a specific user and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and the user's identity information.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail user=$user$ | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType 

[ESCU - Investigate AWS activities via region name - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS activities via region name - Response Task
description = This search lists all the user activities logged by CloudTrail for a specific region in question and will create a table of the values of parameters requested, the type of the event and the response from the AWS API by each user
action.escu.creation_date = 2018-02-09
action.escu.modification_date = 2018-02-09
action.escu.analytic_story = ["AWS Cryptomining", "Cloud Cryptomining", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search lists all the user activities logged by CloudTrail for a specific region in question and will create a table of the values of parameters requested, the type of the event and the response from the AWS API by each user
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail vendor_region=$vendor_region$| rename requestParameters.instancesSet.items{}.instanceId as instanceId | stats values(eventName) by user instanceId vendor_region

[ESCU - Investigate Failed Logins for Multiple Destinations - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Failed Logins for Multiple Destinations - Response Task
description = This search returns failed logins to multiple destinations by user.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search returns failed logins to multiple destinations by user.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats count `security_content_summariesonly` earliest(_time) as first_login latest(_time) as last_login dc(Authentication.dest) AS distinct_count_dest values(Authentication.dest) AS Authentication.dest values(Authentication.app) AS Authentication.app  from datamodel=Authentication where Authentication.action=failure by Authentication.user | where distinct_count_dest > 1 | `security_content_ctime(first_login)` | `security_content_ctime(last_login)` | `drop_dm_object_name("Authentication")` | search user=$user$

[ESCU - Investigate Network Traffic From src ip - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Network Traffic From src ip - Response Task
description = This search allows you to find all the network traffic from a specific IP address.
action.escu.creation_date = 2018-06-15
action.escu.modification_date = 2018-06-15
action.escu.analytic_story = ["ColdRoot MacOS RAT", "Splunk Enterprise Vulnerability CVE-2018-11409"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search allows you to find all the network traffic from a specific IP address.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | from datamodel Network_Traffic.All_Traffic | search src_ip=$src_ip$

[ESCU - Investigate Okta Activity by IP Address - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Okta Activity by IP Address - Response Task
description = This search returns all okta events from a specific IP address.
action.escu.creation_date = 2020-04-02
action.escu.modification_date = 2020-04-02
action.escu.analytic_story = ["Suspicious Okta Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all okta events from a specific IP address.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = eventtype=okta_log src_ip={src_ip} | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | table _time, user, displayMessage, app, src_ip, state, city, result, outcome.reason

[ESCU - Investigate Okta Activity by app - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Okta Activity by app - Response Task
description = This search returns all okta events associated with a specific app
action.escu.creation_date = 2020-04-02
action.escu.modification_date = 2020-04-02
action.escu.analytic_story = ["Suspicious Okta Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all okta events associated with a specific app
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = eventtype=okta_log app=$app$ | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | table _time, user, displayMessage, app, src_ip, state, city, result, outcome.reason

[ESCU - Investigate Pass the Hash Attempts - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Pass the Hash Attempts - Response Task
description = This search hunts for dumped NTLM hashes used for pass the hash.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search hunts for dumped NTLM hashes used for pass the hash.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = `wineventlog_security` EventCode=4624 Logon_Type=9 AuthenticationPackageName=Negotiate | stats count earliest(_time) as first_login latest(_time) as last_login by src_user dest | `security_content_ctime(first_login)` | `security_content_ctime(last_login)` | search dest=$dest$

[ESCU - Investigate Pass the Ticket Attempts - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Pass the Ticket Attempts - Response Task
description = This search hunts for dumped kerberos ticket from LSASS memory.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search hunts for dumped kerberos ticket from LSASS memory.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = `wineventlog_security` EventCode=4768 OR EventCode=4769 | rex field=user "(?<new_user>[^\@]+)" | stats count BY new_user, dest, EventCode | stats max(count) AS max_count sum(count) AS sum_count BY new_user, dest| search dest=$dest$ | where sum_count/max_count!=2 | rename new_user AS user 

[ESCU - Investigate Previous Unseen User - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Previous Unseen User - Response Task
description = This search returns previous unseen user, which didn't log in for 30 days.
action.escu.creation_date = 2019-12-10
action.escu.modification_date = 2019-12-10
action.escu.analytic_story = ["Credential Dumping"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search returns previous unseen user, which didn't log in for 30 days.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats count `security_content_summariesonly` earliest(_time) as first_login latest(_time) as last_login values(Authentication.dest) AS Authentication.dest values(Authentication.app) AS Authentication.app values(Authentication.action) AS Authentication.action from datamodel=Authentication where Authentication.action=success by _time, Authentication.user | bucket _time span=30d | stats count min(first_login) as first_login max(last_login) as last_login values(Authentication.dest) AS Authentication.dest by Authentication.user | where count=1 | where first_login >= relative_time(now(), "-30d") | `security_content_ctime(first_login)` | `security_content_ctime(last_login)` | `drop_dm_object_name("Authentication")` | search dest=$dest$

[ESCU - Investigate Successful Remote Desktop Authentications - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Successful Remote Desktop Authentications - Response Task
description = This search returns the source, destination, and user for all successful remote-desktop authentications. A successful authentication after a brute-force attack on a destination machine is suspicious behavior. 
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Authentication"]
action.escu.eli5 = This search returns the source, destination, and user for all successful remote-desktop authentications. A successful authentication after a brute-force attack on a destination machine is suspicious behavior. 
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Authentication where Authentication.signature_id=4624 Authentication.app=win:remote by Authentication.src Authentication.dest Authentication.app Authentication.user Authentication.signature Authentication.src_nt_domain | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `drop_dm_object_name("Authentication")` | search dest=$dest$ | table firstTime lastTime src src_nt_domain dest user app count | sort count

[ESCU - Investigate Suspicious Strings in HTTP Header - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Suspicious Strings in HTTP Header - Response Task
description = This search helps an analyst investigate a notable event related to a potential Apache Struts exploitation. To investigate, we will want to isolate and analyze the "payload" or the commands that were passed to the vulnerable hosts by creating a few regular expressions to carve out the commands focusing on common keywords from the payload, such as cmd.exe, /bin/bash and whois. The search returns these suspicious strings found in the HTTP logs of the system of interest.
action.escu.creation_date = 2017-10-20
action.escu.modification_date = 2017-10-20
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search helps an analyst investigate a notable event related to a potential Apache Struts exploitation. To investigate, we will want to isolate and analyze the "payload" or the commands that were passed to the vulnerable hosts by creating a few regular expressions to carve out the commands focusing on common keywords from the payload, such as cmd.exe, /bin/bash and whois. The search returns these suspicious strings found in the HTTP logs of the system of interest.
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | search sourcetype=stream:http | search src_ip=$src_ip$ | search dest_ip=$dest_ip$ | eval cs_content_type_length = len(cs_content_type) | search cs_content_type_length > 100 | rex field="cs_content_type" (?<suspicious_strings>cmd.exe) | eval suspicious_strings_found=if(match(cs_content_type, "application"), "True", "False")  | rename suspicious_strings_found AS "Suspicious Content-Type Found" | fields "Suspicious Content-Type Found", dest_ip, src_ip, suspicious_strings, cs_content_type, cs_content_type_length, url

[ESCU - Investigate User Activities In Okta - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate User Activities In Okta - Response Task
description = This search returns all okta events by a specific user
action.escu.creation_date = 2020-04-02
action.escu.modification_date = 2020-04-02
action.escu.analytic_story = ["Suspicious Okta Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = []
action.escu.eli5 = This search returns all okta events by a specific user
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = eventtype=okta_log user=$user$ | rename client.geographicalContext.country as country, client.geographicalContext.state as state, client.geographicalContext.city as city | table _time, user, displayMessage, app, src_ip, state, city, result, outcome.reason

[ESCU - Investigate Web POSTs From src - Response Task]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web POSTs From src - Response Task
description = This investigative search retrieves POST requests from a specified source IP or hostname. Identifying the POST requests, as well as their associated destination URLs and user agent(s), may help you scope and characterize the suspicious traffic. 
action.escu.creation_date = 2018-12-06
action.escu.modification_date = 2018-12-06
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = []
action.escu.data_models = ["Web"]
action.escu.eli5 = This investigative search retrieves POST requests from a specified source IP or hostname. Identifying the POST requests, as well as their associated destination URLs and user agent(s), may help you scope and characterize the suspicious traffic. 
action.escu.how_to_implement = none
action.escu.known_false_positives = None at this time
disabled = true
schedule_window = auto
is_visible = false
search = | tstats `security_content_summariesonly` values(Web.url) as url from datamodel=Web by Web.src,Web.http_user_agent,Web.http_method | `drop_dm_object_name("Web")`| search http_method, "POST" | search src=$src$



### END ESCU RESPONSE TASKS ###

### USAGE DASHBOARD CONFIGURATIONS ###

[escu-metrics-usage]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
dispatchAs = user
search = index=_audit sourcetype="audittrail" \
"ESCU - "\
| stats count(search) by search savedsearch_name user\
| eval usage=(if(savedsearch_name=="","Adhoc","Scheduled")) \
| rex field=search "\"(?<savedsearch_name>.*)\""\
| table savedsearch_name count(search) usage user | join savedsearch_name max=0 type=left [search sourcetype="manifests" | spath searches{} | mvexpand searches{} | spath input=searches{} | table category search_name | rename search_name as savedsearch_name | dedup savedsearch_name] | search category=*

[escu-metrics-search]
action.email.useNSSubject = 1
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
enableSched = 1
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = index=_audit action=search | transaction search_id maxspan=3m | search ESCU | stats sum(total_run_time) avg(total_run_time) max(total_run_time) sum(result_count)

[escu-metrics-search-events]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
enableSched = 1
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = [search index=_audit sourcetype="audittrail" \"ESCU NOT "index=_audit" | where search !="" | dedup search_id | rex field=search "\"(?<search_name>.*)\"" | rex field=_raw "user=(?<user>[a-zA-Z0-9_\-]+)" | eval usage=if(savedsearch_name!="", "scheduled", "adhoc") | eval savedsearch_name=if(savedsearch_name != "", savedsearch_name, search_name) | table savedsearch_name search_id user _time usage | outputlookup escu_search_id.csv | table search_id] index=_audit total_run_time event_count result_count NOT "index=_audit" | lookup escu_search_id.csv search_id | stats count(savedsearch_name) AS search_count avg(total_run_time) AS search_avg_run_time sum(total_run_time) AS search_total_run_time sum(result_count) AS search_total_results earliest(_time) AS firsts latest(_time) AS lasts by savedsearch_name user usage| eval first_run=strftime(firsts, "%B %d %Y") | eval last_run=strftime(lasts, "%B %d %Y")

[escu-metrics-search-longest-runtime]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
enableSched = 1
cron_schedule = 0 0 * * *
disabled = 1
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = index=_* ESCU [search index=_* action=search latest=-2h earliest=-1d| transaction search_id maxspan=3m | search ESCU | stats values(total_run_time) AS run by search_id | sort -run | head 1| table search_id] | table search search_id

[escu-metrics-usage-search]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
enableSched = 1
dispatchAs = user
search = index=_audit sourcetype="audittrail" \
"ESCU - "\
| stats count(search) by search savedsearch_name user\
| eval usage=(if(savedsearch_name=="","Adhoc","Scheduled")) \
| rex field=search "\"(?<savedsearch_name>.*)\""\
| table savedsearch_name count(search) usage user | join savedsearch_name max=0 type=left [search sourcetype="manifests" | spath searches{} | mvexpand searches{} | spath input=searches{} | table category search_name | rename search_name as savedsearch_name | dedup savedsearch_name] | search category=*

### END OF USAGE DASHBOARD CONFIGURATIONS ###