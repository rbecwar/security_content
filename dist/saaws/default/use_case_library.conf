#############
# Automatically generated by generator.py in splunk/security_content
# On Date: 2021-03-30T19:36:01 UTC
# Author: Splunk Security Research
# Contact: research@splunk.com
#############

### STORIES ###

[analytic_story://AWS IAM Privilege Escalation]
category = Cloud Security
last_updated = 2021-03-08
version = 1
references = ["https://rhinosecuritylabs.com/aws/aws-privilege-escalation-methods-mitigation/", "https://www.cyberark.com/resources/threat-research-blog/the-cloud-shadow-admin-threat-10-permissions-to-protect", "https://labs.bishopfox.com/tech-blog/privilege-escalation-in-aws"]
maintainers = [{"company": "Splunk", "email": "-", "name": "Bhavin Patel"}]
spec_version = 3
searches = ["ESCU - AWS CreateLoginProfile - Rule", "ESCU - AWS UpdateLoginProfile - Rule", "ESCU - AWS CreateAccessKey - Rule", "ESCU - AWS Create Policy Version to allow all resources - Rule", "ESCU - AWS SetDefaultPolicyVersion - Rule"]
description = This analytic story contains detections that query your AWS Cloudtrail for activities related to privilege escalation.
narrative = Amazon Web Services provides a neat feature called Identity and Access Management (IAM) that enables organizations to manage various AWS services and resources in a secure way. All IAM users have roles, groups and policies associated with them which governs and sets permissions to allow a user to access specific restrictions.\
However, if these IAM policies are misconfigured and have specific combinations of weak permissions; it can allow attackers to escalate their privileges and further compromise the organization. Rhino Security Labs have published comprehensive blogs detailing various AWS Escalation methods. By using this as an inspiration, Splunkâ€™s research team wants to highlight how these attack vectors look in AWS Cloudtrail logs and provide you with detection queries to uncover these potentially malicious events via this Analytic Story. \

[analytic_story://AWS Network ACL Activity]
category = Cloud Security
last_updated = 2018-05-21
version = 2
references = ["https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_NACLs.html", "https://aws.amazon.com/blogs/security/how-to-help-prepare-for-ddos-attacks-by-reducing-your-attack-surface/"]
maintainers = [{"company": "Splunk", "email": "-", "name": "Bhavin Patel"}]
spec_version = 3
searches = ["ESCU - AWS Network Access Control List Created with All Open Ports - Rule", "ESCU - AWS Network Access Control List Deleted - Rule", "ESCU - Get Process Info - Response Task", "ESCU - Get Notable History - Response Task", "ESCU - AWS Investigate User Activities By ARN - Response Task", "ESCU - Get DNS traffic ratio - Response Task", "ESCU - Get DNS Server History for a host - Response Task", "ESCU - AWS Network ACL Details from ID - Response Task", "ESCU - Get Process Responsible For The DNS Traffic - Response Task", "ESCU - Get All AWS Activity From IP Address - Response Task", "ESCU - AWS Network Interface details via resourceId - Response Task", "ESCU - Get Process Information For Port Activity - Response Task"]
description = Monitor your AWS network infrastructure for bad configurations and malicious activity. Investigative searches help you probe deeper, when the facts warrant it.
narrative = AWS CloudTrail is an AWS service that helps you enable governance, compliance, and operational/risk auditing of your AWS account. Actions taken by a user, role, or an AWS service are recorded as events in CloudTrail. It is crucial for a company to monitor events and actions taken in the AWS Management Console, AWS Command Line Interface, and AWS SDKs and APIs to ensure that your servers are not vulnerable to attacks. This analytic story contains detection searches that leverage CloudTrail logs from AWS to check for bad configurations and malicious activity in your AWS network access controls.

[analytic_story://AWS Security Hub Alerts]
category = Cloud Security
last_updated = 2020-08-04
version = 1
references = ["https://aws.amazon.com/security-hub/features/"]
maintainers = [{"company": "Splunk", "email": "-", "name": "Bhavin Patel"}]
spec_version = 3
searches = ["ESCU - Detect Spike in AWS Security Hub Alerts for EC2 Instance - Rule", "ESCU - Get EC2 Instance Details by instanceId - Response Task", "ESCU - Get EC2 Launch Details - Response Task", "ESCU - AWS Investigate User Activities By ARN - Response Task"]
description = This story is focused around detecting Security Hub alerts generated from AWS
narrative = AWS Security Hub collects and consolidates findings from AWS security services enabled in your environment, such as intrusion detection findings from Amazon GuardDuty, vulnerability scans from Amazon Inspector, S3 bucket policy findings from Amazon Macie, publicly accessible and cross-account resources from IAM Access Analyzer, and resources lacking WAF coverage from AWS Firewall Manager.

[analytic_story://Cloud Cryptomining]
category = Cloud Security
last_updated = 2019-10-02
version = 1
references = ["https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf"]
maintainers = [{"company": "Splunk", "email": "-", "name": "David Dorsey"}]
spec_version = 3
searches = ["ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule", "ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule", "ESCU - Abnormally High Number Of Cloud Instances Launched - Rule", "ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule", "ESCU - Cloud Compute Instance Created In Previously Unused Region - Rule", "ESCU - Investigate AWS activities via region name - Response Task", "ESCU - Get EC2 Launch Details - Response Task", "ESCU - Get EC2 Instance Details by instanceId - Response Task", "ESCU - AWS Investigate User Activities By ARN - Response Task", "ESCU - AWS Investigate Security Hub alerts by dest - Response Task", "ESCU - Get Notable History - Response Task"]
description = Monitor your cloud compute instances for activities related to cryptojacking/cryptomining. New instances that originate from previously unseen regions, users who launch abnormally high numbers of instances, or compute instances started by previously unseen users are just a few examples of potentially malicious behavior.
narrative = Cryptomining is an intentionally difficult, resource-intensive business. Its complexity was designed into the process to ensure that the number of blocks mined each day would remain steady. So, it's par for the course that ambitious, but unscrupulous, miners make amassing the computing power of large enterprises--a practice known as cryptojacking--a top priority. \
Cryptojacking has attracted an increasing amount of media attention since its explosion in popularity in the fall of 2017. The attacks have moved from in-browser exploits and mobile phones to enterprise cloud services, such as Amazon Web Services (AWS), Google Cloud Platform (GCP), and Azure. It's difficult to determine exactly how widespread the practice has become, since bad actors continually evolve their ability to escape detection, including employing unlisted endpoints, moderating their CPU usage, and hiding the mining pool's IP address behind a free CDN. \
When malicious miners appropriate a cloud instance, often spinning up hundreds of new instances, the costs can become astronomical for the account holder. So it is critically important to monitor your systems for suspicious activities that could indicate that your network has been infiltrated. \
This Analytic Story is focused on detecting suspicious new instances in your cloud environment to help prevent cryptominers from gaining a foothold. It contains detection searches that will detect when a previously unused instance type or AMI is used. It also contains support searches to build lookup files to ensure proper execution of the detection searches.

[analytic_story://Cloud Federated Credential Abuse]
category = Cloud Security
last_updated = 2021-01-26
version = 1
references = ["https://www.cyberark.com/resources/threat-research-blog/golden-saml-newly-discovered-attack-technique-forges-authentication-to-cloud-apps", "https://www.fireeye.com/content/dam/fireeye-www/blog/pdfs/wp-m-unc2452-2021-000343-01.pdf", "https://us-cert.cisa.gov/ncas/alerts/aa21-008a"]
maintainers = [{"company": "Splunk", "email": "-", "name": "Rod Soto"}]
spec_version = 3
searches = ["ESCU - O365 Added Service Principal - Rule", "ESCU - O365 Excessive SSO logon errors - Rule", "ESCU - O365 New Federated Domain Added - Rule", "ESCU - AWS SAML Update identity provider - Rule", "ESCU - AWS SAML Access by Provider User and Principal - Rule", "ESCU - O365 Add App Role Assignment Grant User - Rule"]
description = This analytical story addresses events that indicate abuse of cloud federated credentials. These credentials are usually extracted from endpoint desktop or servers specially those servers that provide federation services such as Windows Active Directory Federation Services. Identity Federation relies on objects such as Oauth2 tokens, cookies or SAML assertions in order to provide seamless access between cloud and perimeter environments. If these objects are either hijacked or forged then attackers will be able to pivot into victim's cloud environements.
narrative = This story is composed of detection searches based on endpoint that addresses the use of Mimikatz, Escalation of Privileges and Abnormal processes that may indicate the extraction of Federated directory objects such as passwords, Oauth2 tokens, certificates and keys. Cloud environment (AWS, Azure) related events are also addressed in specific cloud environment detection searches.

[analytic_story://Office 365 Detections]
category = Cloud Security
last_updated = 2020-12-16
version = 1
references = ["https://i.blackhat.com/USA-20/Thursday/us-20-Bienstock-My-Cloud-Is-APTs-Cloud-Investigating-And-Defending-Office-365.pdf"]
maintainers = [{"company": "Splunk", "email": "-", "name": "Patrick Bareiss"}]
spec_version = 3
searches = ["ESCU - O365 Added Service Principal - Rule", "ESCU - O365 Disable MFA - Rule", "ESCU - O365 Excessive SSO logon errors - Rule", "ESCU - O365 New Federated Domain Added - Rule", "ESCU - O365 Suspicious Admin Email Forwarding - Rule", "ESCU - O365 PST export alert - Rule", "ESCU - O365 Suspicious Rights Delegation - Rule", "ESCU - O365 Add App Role Assignment Grant User - Rule", "ESCU - O365 Suspicious User Email Forwarding - Rule", "ESCU - O365 Excessive Authentication Failures Alert - Rule", "ESCU - O365 Bypass MFA via Trusted IP - Rule"]
description = This story is focused around detecting Office 365 Attacks.
narrative = More and more companies are using Microsofts Office 365 cloud offering. Therefore, we see more and more attacks against Office 365. This story provides various detections for Office 365 attacks.

[analytic_story://Ransomware Cloud]
category = Malware
last_updated = 2020-10-27
version = 1
references = ["https://rhinosecuritylabs.com/aws/s3-ransomware-part-1-attack-vector/", "https://github.com/d1vious/git-wild-hunt", "https://www.youtube.com/watch?v=PgzNib37g0M"]
maintainers = [{"company": "David Dorsey, Splunk", "email": "-", "name": "Rod Soto"}]
spec_version = 3
searches = ["ESCU - AWS Detect Users creating keys with encrypt policy without MFA - Rule", "ESCU - AWS Detect Users with KMS keys performing encryption S3 - Rule", "ESCU - Get Notable History - Response Task"]
description = Leverage searches that allow you to detect and investigate unusual activities that might relate to ransomware. These searches include cloud related objects that may be targeted by malicious actors via cloud providers own encryption features.
narrative = Ransomware is an ever-present risk to the enterprise, wherein an infected host encrypts business-critical data, holding it hostage until the victim pays the attacker a ransom. There are many types and varieties of ransomware that can affect an enterprise.Cloud ransomware can be deployed by obtaining high privilege credentials from targeted users or resources.

[analytic_story://Suspicious AWS Login Activities]
category = Cloud Security
last_updated = 2019-05-01
version = 1
references = ["https://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html"]
maintainers = [{"company": "Splunk", "email": "-", "name": "Bhavin Patel"}]
spec_version = 3
searches = ["ESCU - Detect AWS Console Login by User from New Region - Rule", "ESCU - Detect AWS Console Login by User from New City - Rule", "ESCU - Detect AWS Console Login by User from New Country - Rule", "ESCU - AWS Investigate User Activities By ARN - Response Task"]
description = Monitor your AWS authentication events using your CloudTrail logs. Searches within this Analytic Story will help you stay aware of and investigate suspicious logins. 
narrative = It is important to monitor and control who has access to your AWS infrastructure. Detecting suspicious logins to your AWS infrastructure will provide good starting points for investigations. Abusive behaviors caused by compromised credentials can lead to direct monetary costs, as you will be billed for any EC2 instances created by the attacker.

[analytic_story://Suspicious AWS S3 Activities]
category = Cloud Security
last_updated = 2018-07-24
version = 2
references = ["https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf", "https://www.tripwire.com/state-of-security/security-data-protection/cloud/public-aws-s3-buckets-writable/"]
maintainers = [{"company": "Splunk", "email": "-", "name": "Bhavin Patel"}]
spec_version = 3
searches = ["ESCU - Detect New Open S3 buckets - Rule", "ESCU - Detect New Open S3 Buckets over AWS CLI - Rule", "ESCU - Investigate AWS activities via region name - Response Task", "ESCU - AWS Investigate User Activities By ARN - Response Task", "ESCU - AWS S3 Bucket details via bucketName - Response Task", "ESCU - Get All AWS Activity From IP Address - Response Task", "ESCU - Get Notable History - Response Task"]
description = Use the searches in this Analytic Story to monitor your AWS S3 buckets for evidence of anomalous activity and suspicious behaviors, such as detecting open S3 buckets and buckets being accessed from a new IP. The contextual and investigative searches will give you more information, when required.
narrative = As cloud computing has exploded, so has the number of creative attacks on virtual environments. And as the number-two cloud-service provider, Amazon Web Services (AWS) has certainly had its share.\
Amazon's "shared responsibility" model dictates that the company has responsibility for the environment outside of the VM and the customer is responsible for the security inside of the S3 container. As such, it's important to stay vigilant for activities that may belie suspicious behavior inside of your environment.\
Among things to look out for are S3 access from unfamiliar locations and by unfamiliar users. Some of the searches in this Analytic Story help you detect suspicious behavior and others help you investigate more deeply, when the situation warrants.   

[analytic_story://Suspicious Cloud Authentication Activities]
category = Cloud Security
last_updated = 2020-06-04
version = 1
references = ["https://aws.amazon.com/blogs/security/aws-cloudtrail-now-tracks-cross-account-activity-to-its-origin/", "https://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html"]
maintainers = [{"company": "Splunk", "email": "-", "name": "Rico Valdez"}]
spec_version = 3
searches = ["ESCU - Detect AWS Console Login by New User - Rule", "ESCU - Detect AWS Console Login by User from New Country - Rule", "ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule", "ESCU - Detect AWS Console Login by User from New Region - Rule", "ESCU - Detect AWS Console Login by User from New City - Rule", "ESCU - Investigate AWS User Activities by user field - Response Task", "ESCU - Get Notable History - Response Task"]
description = Monitor your cloud authentication events. Searches within this Analytic Story leverage the recent cloud updates to the Authentication data model to help you stay aware of and investigate suspicious login activity. 
narrative = It is important to monitor and control who has access to your cloud infrastructure. Detecting suspicious logins will provide good starting points for investigations. Abusive behaviors caused by compromised credentials can lead to direct monetary costs, as you will be billed for any compute activity whether legitimate or otherwise.\
This Analytic Story has data model versions of cloud searches leveraging Authentication data, including those looking for suspicious login activity, and cross-account activity for AWS.

[analytic_story://Suspicious Cloud Instance Activities]
category = Cloud Security
last_updated = 2020-08-25
version = 1
references = ["https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf"]
maintainers = [{"company": "Splunk", "email": "-", "name": "David Dorsey"}]
spec_version = 3
searches = ["ESCU - Abnormally High Number Of Cloud Instances Launched - Rule", "ESCU - Cloud Instance Modified By Previously Unseen User - Rule", "ESCU - Abnormally High Number Of Cloud Instances Destroyed - Rule", "ESCU - Get All AWS Activity From IP Address - Response Task", "ESCU - AWS Investigate User Activities By ARN - Response Task"]
description = Monitor your cloud infrastructure provisioning activities for behaviors originating from unfamiliar or unusual locations. These behaviors may indicate that malicious activities are occurring somewhere within your cloud environment.
narrative = Monitoring your cloud infrastructure logs allows you enable governance, compliance, and risk auditing. It is crucial for a company to monitor events and actions taken in the their cloud environments to ensure that your instances are not vulnerable to attacks. This Analytic Story identifies suspicious activities in your cloud compute instances and helps you respond and investigate those activities.

[analytic_story://Suspicious Cloud Provisioning Activities]
category = Cloud Security
last_updated = 2018-08-20
version = 1
references = ["https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf"]
maintainers = [{"company": "Splunk", "email": "-", "name": "David Dorsey"}]
spec_version = 3
searches = ["ESCU - Cloud Provisioning Activity From Previously Unseen Region - Rule", "ESCU - Cloud Provisioning Activity From Previously Unseen Country - Rule", "ESCU - Cloud Provisioning Activity From Previously Unseen IP Address - Rule", "ESCU - Cloud Provisioning Activity From Previously Unseen City - Rule", "ESCU - Get Notable History - Response Task"]
description = Monitor your cloud infrastructure provisioning activities for behaviors originating from unfamiliar or unusual locations. These behaviors may indicate that malicious activities are occurring somewhere within your cloud environment.
narrative = Because most enterprise cloud infrastructure activities originate from familiar geographic locations, monitoring for activity from unknown or unusual regions is an important security measure. This indicator can be especially useful in environments where it is impossible to add specific IPs to an allow list because they vary.\
This Analytic Story was designed to provide you with flexibility in the precision you employ in specifying legitimate geographic regions. It can be as specific as an IP address or a city, or as broad as a region (think state) or an entire country. By determining how precise you want your geographical locations to be and monitoring for new locations that haven't previously accessed your environment, you can detect adversaries as they begin to probe your environment. Since there are legitimate reasons for activities from unfamiliar locations, this is not a standalone indicator. Nevertheless, location can be a relevant piece of information that you may wish to investigate further.

[analytic_story://Suspicious Cloud User Activities]
category = Cloud Security
last_updated = 2020-09-04
version = 1
references = ["https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf", "https://redlock.io/blog/cryptojacking-tesla"]
maintainers = [{"company": "Splunk", "email": "-", "name": "David Dorsey"}]
spec_version = 3
searches = ["ESCU - Abnormally High Number Of Cloud Security Group API Calls - Rule", "ESCU - Cloud API Calls From Previously Unseen User Roles - Rule", "ESCU - Abnormally High Number Of Cloud Infrastructure API Calls - Rule", "ESCU - AWS Investigate User Activities By ARN - Response Task"]
description = Detect and investigate suspicious activities by users and roles in your cloud environments.
narrative = It seems obvious that it is critical to monitor and control the users who have access to your cloud infrastructure. Nevertheless, it's all too common for enterprises to lose track of ad-hoc accounts, leaving their servers vulnerable to attack. In fact, this was the very oversight that led to Tesla's cryptojacking attack in February, 2018.\
In addition to compromising the security of your data, when bad actors leverage your compute resources, it can incur monumental costs, since you will be billed for any new instances and increased bandwidth usage.

### END STORIES ###

### DETECTIONS ###

[savedsearch://ESCU - AWS Create Policy Version to allow all resources - Rule]
type = detection
asset_type = AWS Account
confidence = medium
explanation = This search looks for CloudTrail events where a user created a policy version that allows them to access any resource in their account
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a policy to allow a user to access all resources. That said, AWS strongly advises against granting full control to all AWS resources
providing_technologies = []

[savedsearch://ESCU - AWS CreateAccessKey - Rule]
type = detection
asset_type = AWS Account
confidence = medium
explanation = This search looks for CloudTrail events where a user A who has already permission to create access keys, makes an API call to create access keys for another user B. Attackers have been know to use this technique for Privilege Escalation in case new victim(user B) has more permissions than old victim(user B)
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created keys for another user.
providing_technologies = []

[savedsearch://ESCU - AWS CreateLoginProfile - Rule]
type = detection
asset_type = AWS Account
confidence = medium
explanation = This search looks for CloudTrail events where a user A(victim A) creates a login profile for user B, followed by a AWS Console login event from user B from the same src_ip as user B. This correlated event can be indicative of privilege escalation since both events happened from the same src_ip
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a login profile for another user.
providing_technologies = []

[savedsearch://ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.  This search is deprecated and have been translated to use the latest Authentication Datamodel.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen AWS Cross Account Activity - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen AWS Cross Account Activity - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `aws_cross_account_activity_from_previously_unseen_account_filter` macro.
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
known_false_positives = Using multiple AWS accounts and roles is perfectly valid behavior. It's suspicious when an account requests privileges of an account it hasn't before. You should validate with the account owner that this is a legitimate request.
providing_technologies = []

[savedsearch://ESCU - AWS Detect Users creating keys with encrypt policy without MFA - Rule]
type = detection
asset_type = AWS Account
confidence = medium
explanation = This search provides detection of KMS keys which action kms:Encrypt is accessible for everyone (also outside of your organization). This is an identicator that your account is compromised and the attacker uses the encryption key to compromise another company.
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs
annotations = {"mitre_attack": ["T1486"]}
known_false_positives = unknown
providing_technologies = []

[savedsearch://ESCU - AWS Detect Users with KMS keys performing encryption S3 - Rule]
type = detection
asset_type = S3 Bucket
confidence = medium
explanation = This search provides detection of users with KMS keys performing encryption specifically against S3 buckets.
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs
annotations = {"mitre_attack": ["T1486"]}
known_false_positives = bucket with S3 encryption
providing_technologies = []

[savedsearch://ESCU - AWS Network Access Control List Created with All Open Ports - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS, version 4.4.0 or later, and configure your CloudTrail inputs.
annotations = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1562.007"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = It's possible that an admin has created this ACL with all ports open for some legitimate purpose however, this should be scoped and not allowed in production environment.
providing_technologies = []

[savedsearch://ESCU - AWS Network Access Control List Deleted - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
annotations = {"cis20": ["CIS 11"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1562.007"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = It's possible that a user has legitimately deleted a network ACL.
providing_technologies = []

[savedsearch://ESCU - AWS SAML Access by Provider User and Principal - Rule]
type = detection
asset_type = AWS Federated Account
confidence = medium
explanation = This search provides specific SAML access from specific Service Provider, user and targeted principal at AWS. This search provides specific information to detect abnormal access or potential credential hijack or forgery, specially in federated environments using SAML protocol inside the perimeter or cloud provider.
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs
annotations = {"mitre_attack": ["T1078"]}
known_false_positives = Attacks using a Golden SAML or SAML assertion hijacks or forgeries are very difficult to detect as accessing cloud providers with these assertions looks exactly like normal access, however things such as source IP sourceIPAddress user, and principal targeted at receiving cloud provider along with endpoint credential access and abuse detection searches can provide the necessary context to detect these attacks.
providing_technologies = []

[savedsearch://ESCU - AWS SAML Update identity provider - Rule]
type = detection
asset_type = AWS Federated Account
confidence = medium
explanation = This search provides detection of updates to SAML provider in AWS. Updates to SAML provider need to be monitored closely as they may indicate possible perimeter compromise of federated credentials, or backdoor access from another cloud provider set by attacker.
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
annotations = {"mitre_attack": ["T1078"]}
known_false_positives = Updating a SAML provider or creating a new one may not necessarily be malicious however it needs to be closely monitored.
providing_technologies = []

[savedsearch://ESCU - AWS SetDefaultPolicyVersion - Rule]
type = detection
asset_type = AWS Account
confidence = medium
explanation = This search looks for CloudTrail events where a user has set a default policy versions. Attackers have been know to use this technique for Privilege Escalation in case the previous versions of the policy had permissions to access more resources than the current version of the policy
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately set a default policy to allow a user to access all resources. That said, AWS strongly advises against granting full control to all AWS resources
providing_technologies = []

[savedsearch://ESCU - AWS UpdateLoginProfile - Rule]
type = detection
asset_type = AWS Account
confidence = medium
explanation = This search looks for CloudTrail events where a user A who has already permission to update login profile, makes an API call to update login profile for another user B . Attackers have been know to use this technique for Privilege Escalation in case new victim(user B) has more permissions than old victim(user B)
how_to_implement = You must install splunk AWS add on and Splunk App for AWS. This search works with cloudtrail logs.
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1136.003"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created keys for another user.
providing_technologies = []

[savedsearch://ESCU - Abnormally High Number Of Cloud Infrastructure API Calls - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search will detect a spike in the number of API calls made to your cloud infrastructure environment by a user.
how_to_implement = You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Infrastructure API Calls Per User` to create the probability density function.
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
known_false_positives = 
providing_technologies = []

[savedsearch://ESCU - Abnormally High Number Of Cloud Instances Destroyed - Rule]
type = detection
asset_type = Cloud Instance
confidence = medium
explanation = This search finds for the number successfully destroyed cloud instances for every 4 hour block. This is split up between weekdays and the weekend. It then applies the probability densitiy model previously created and alerts on any outliers.
how_to_implement = You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Instances Destroyed` to create the probability density function.
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = Many service accounts configured within a cloud infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
providing_technologies = []

[savedsearch://ESCU - Abnormally High Number Of Cloud Instances Launched - Rule]
type = detection
asset_type = Cloud Instance
confidence = medium
explanation = This search finds for the number successfully created cloud instances for every 4 hour block. This is split up between weekdays and the weekend. It then applies the probability densitiy model previously created and alerts on any outliers.
how_to_implement = You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Instances Launched` to create the probability density function.
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
providing_technologies = []

[savedsearch://ESCU - Abnormally High Number Of Cloud Security Group API Calls - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search will detect a spike in the number of API calls made to your cloud infrastructure environment about security groups by a user.
how_to_implement = You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Security Group API Calls Per User` to create the probability density function model.
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1078.004"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
known_false_positives = 
providing_technologies = []

[savedsearch://ESCU - Cloud API Calls From Previously Unseen User Roles - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for new commands from each user role.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud API Calls Per User Role - Initial` to build the initial table of user roles, commands, and times. You must also enable the second baseline search `Previously Seen Cloud API Calls Per User Role - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `cloud_api_calls_from_previously_unseen_user_roles_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_api_calls_from_previously_unseen_user_roles_filter`
annotations = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
known_false_positives = .
providing_technologies = []

[savedsearch://ESCU - Cloud Compute Instance Created By Previously Unseen User - Rule]
type = detection
asset_type = Cloud Compute Instance
confidence = medium
explanation = This search looks for cloud compute instances created by users who have not created them before.
how_to_implement = You must be ingesting the appropriate cloud-infrastructure logs Run the "Previously Seen Cloud Compute Creations By User" support search to create of baseline of previously seen users.
annotations = {"cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
known_false_positives = It's possible that a user will start to create compute instances for the first time, for any number of reasons. Verify with the user launching instances that this is the intended behavior.
providing_technologies = []

[savedsearch://ESCU - Cloud Compute Instance Created In Previously Unused Region - Rule]
type = detection
asset_type = Cloud Compute Instance
confidence = medium
explanation = This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Regions - Initial` to build the initial table of images observed and times. You must also enable the second baseline search `Previously Seen Cloud Regions - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_in_previously_unused_region_filter` macro.
annotations = {"cis20": ["CIS 12"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.
providing_technologies = []

[savedsearch://ESCU - Cloud Compute Instance Created With Previously Unseen Image - Rule]
type = detection
asset_type = Cloud Compute Instance
confidence = medium
explanation = This search looks for cloud compute instances being created with previously unseen image IDs.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Compute Images - Initial` to build the initial table of images observed and times. You must also enable the second baseline search `Previously Seen Cloud Compute Images - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_with_previously_unseen_image_filter` macro.
annotations = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
known_false_positives = After a new image is created, the first systems created with that image will cause this alert to fire.  Verify that the image being used was created by a legitimate user.
providing_technologies = []

[savedsearch://ESCU - Cloud Compute Instance Created With Previously Unseen Instance Type - Rule]
type = detection
asset_type = Cloud Compute Instance
confidence = medium
explanation = Find EC2 instances being created with previously unseen instance types.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Compute Instance Types - Initial` to build the initial table of instance types observed and times. You must also enable the second baseline search `Previously Seen Cloud Compute Instance Types - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_with_previously_unseen_instance_type_filter` macro.
annotations = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
known_false_positives = It is possible that an admin will create a new system using a new instance type that has never been used before. Verify with the creator that they intended to create the system with the new instance type.
providing_technologies = []

[savedsearch://ESCU - Cloud Instance Modified By Previously Unseen User - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for cloud instances being modified by users who have not previously modified them.
how_to_implement = This search has a dependency on other searches to create and update a baseline of users observed to be associated with this activity. The search "Previously Seen Cloud Instance Modifications By User - Update" should be enabled for this detection to properly work.
annotations = {"cis20": ["CIS 1"], "mitre_attack": ["T1078.004"], "nist": ["ID.AM"]}
known_false_positives = It's possible that a new user will start to modify EC2 instances when they haven't before for any number of reasons. Verify with the user that is modifying instances that this is the intended behavior.
providing_technologies = []

[savedsearch://ESCU - Cloud Provisioning Activity From Previously Unseen City - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for cloud provisioning activities from previously unseen cities. Provisioning activities are defined broadly as any event that runs or creates something.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_city_filter` macro.
annotations = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
providing_technologies = []

[savedsearch://ESCU - Cloud Provisioning Activity From Previously Unseen Country - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for cloud provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that runs or creates something.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_country_filter` macro.
annotations = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
providing_technologies = []

[savedsearch://ESCU - Cloud Provisioning Activity From Previously Unseen IP Address - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for cloud provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that runs or creates something.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_ip_address_filter` macro.
annotations = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
providing_technologies = []

[savedsearch://ESCU - Cloud Provisioning Activity From Previously Unseen Region - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for cloud provisioning activities from previously unseen regions. Provisioning activities are defined broadly as any event that runs or creates something.
how_to_implement = You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_region_filter` macro.
annotations = {"cis20": ["CIS 1"], "mitre_attack": ["T1078"], "nist": ["ID.AM"]}
known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
providing_technologies = []

[savedsearch://ESCU - Detect AWS Console Login by New User - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
providing_technologies = []

[savedsearch://ESCU - Detect AWS Console Login by User from New City - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_city_filter` macro.
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
providing_technologies = []

[savedsearch://ESCU - Detect AWS Console Login by User from New Country - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_country_filter` macro.
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
providing_technologies = []

[savedsearch://ESCU - Detect AWS Console Login by User from New Region - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_region_filter` macro.
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1535"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
providing_technologies = []

[savedsearch://ESCU - Detect New Open S3 Buckets over AWS CLI - Rule]
type = detection
asset_type = S3 Bucket
confidence = medium
explanation = This search looks for CloudTrail events where a user has created an open/public S3 bucket over the aws cli.
how_to_implement = 
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the "All Users" group.
providing_technologies = []

[savedsearch://ESCU - Detect New Open S3 buckets - Rule]
type = detection
asset_type = S3 Bucket
confidence = medium
explanation = This search looks for CloudTrail events where a user has created an open/public S3 bucket.
how_to_implement = You must install the AWS App for Splunk.
annotations = {"cis20": ["CIS 13"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1530"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the "All Users" group.
providing_technologies = []

[savedsearch://ESCU - Detect Spike in AWS Security Hub Alerts for EC2 Instance - Rule]
type = detection
asset_type = AWS Instance
confidence = medium
explanation = This search looks for a spike in number of of AWS security Hub alerts for an EC2 instance in 4 hours intervals
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Security Hub inputs. The threshold_value should be tuned to your environment and schedule these searches according to the bucket span interval.
annotations = {"cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = None
providing_technologies = []

[savedsearch://ESCU - O365 Add App Role Assignment Grant User - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects the creation of a new Federation setting by alerting about an specific event related to its creation.
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
known_false_positives = The creation of a new Federation is not necessarily malicious, however this events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a different cloud provider.
providing_technologies = []

[savedsearch://ESCU - O365 Added Service Principal - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects the creation of a new Federation setting by alerting about an specific event related to its creation.
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
known_false_positives = The creation of a new Federation is not necessarily malicious, however these events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a different cloud provider.
providing_technologies = []

[savedsearch://ESCU - O365 Bypass MFA via Trusted IP - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects newly added IP addresses/CIDR blocks to the list of MFA Trusted IPs to bypass multi factor authentication. Attackers are often known to use this technique so that they can bypass the MFA system.
how_to_implement = You must install Splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1562.007"]}
known_false_positives = Unless it is a special case, it is uncommon to continually update Trusted IPs to MFA configuration.
providing_technologies = []

[savedsearch://ESCU - O365 Disable MFA - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects when multi factor authentication has been disabled, what entitiy performed the action and against what user
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1556"]}
known_false_positives = Unless it is a special case, it is uncommon to disable MFA or Strong Authentication
providing_technologies = []

[savedsearch://ESCU - O365 Excessive Authentication Failures Alert - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects when an excessive number of authentication failures occur this search also includes attempts against MFA prompt codes
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"kill_chain_phases": ["Not Applicable"], "mitre_attack": ["T1110"]}
known_false_positives = The threshold for alert is above 10 attempts and this should reduce the number of false positives.
providing_technologies = []

[savedsearch://ESCU - O365 Excessive SSO logon errors - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects accounts with high number of Single Sign ON (SSO) logon errors. Excessive logon errors may indicate attempts to bruteforce of password or single sign on token hijack or reuse.
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1556"]}
known_false_positives = Logon errors may not be malicious in nature however it may indicate attempts to reuse a token or password obtained via credential access attack.
providing_technologies = []

[savedsearch://ESCU - O365 New Federated Domain Added - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects the addition of a new Federated domain.
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity.
annotations = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1136.003"]}
known_false_positives = The creation of a new Federated domain is not necessarily malicious, however these events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a similar or different cloud provider.
providing_technologies = []

[savedsearch://ESCU - O365 PST export alert - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects when a user has performed an Ediscovery search or exported a PST file from the search. This PST file usually has sensitive information including email body content
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"kill_chain_phases": ["Actions on Objective"], "mitre_attack": ["T1114"]}
known_false_positives = PST export can be done for legitimate purposes but due to the sensitive nature of its content it must be monitored.
providing_technologies = []

[savedsearch://ESCU - O365 Suspicious Admin Email Forwarding - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects when an admin configured a forwarding rule for multiple mailboxes to the same destination.
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.003"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = unknown
providing_technologies = []

[savedsearch://ESCU - O365 Suspicious Rights Delegation - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects the assignment of rights to accesss content from another mailbox. This is usually only assigned to a service account.
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.002"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = Service Accounts
providing_technologies = []

[savedsearch://ESCU - O365 Suspicious User Email Forwarding - Rule]
type = detection
asset_type = Office 365
confidence = medium
explanation = This search detects when multiple user configured a forwarding rule to the same destination.
how_to_implement = You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity
annotations = {"cis20": ["CIS 16"], "kill_chain_phases": ["Actions on Objectives"], "mitre_attack": ["T1114.003"], "nist": ["DE.DP", "DE.AE"]}
known_false_positives = unknown
providing_technologies = []

### END DETECTIONS ###

### RESPONSE TASKS ###

[savedsearch://ESCU - AWS Investigate Security Hub alerts by dest - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - AWS Investigate User Activities By ARN - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - AWS Investigate User Activities By AccessKeyId - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - AWS Network ACL Details from ID - Response Task]
type = investigation
explanation = none
how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - AWS Network Interface details via resourceId - Response Task]
type = investigation
explanation = none
how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS configuration inputs
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - AWS S3 Bucket details via bucketName - Response Task]
type = investigation
explanation = none
how_to_implement = To implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later) and configure your AWS inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - All backup logs for host - Response Task]
type = investigation
explanation = none
how_to_implement = The successfully implement this search you must first send your backup logs to Splunk.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Amazon EKS Kubernetes activity by src ip - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Cloud Watch EKS inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - DNS Hijack Enrichment - Response Task]
type = investigation
explanation = none
how_to_implement = If Splunk>Phantom is also configured in your environment, a Playbook called "DNS Hijack Enrichment" can be configured to run when any results are found by this detection search. The playbook takes in the DNS record changed and uses Geoip, whois, Censys and PassiveTotal to detect if DNS issuers changed. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
(Playbook Link:`https://my.phantom.us/4.2/playbook/dns-hijack-enrichment/`).\

known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Domain Certificate Investigation - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this phantom playbook, you must integrate Enterprise Security with Phantom. Configure this playbook in the correlation search `Detect DNS requests to Phishing Sites leveraging EvilGinx2` ,as an adaptive response action.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Excessive Account Lockouts Enrichment And Response - Response Task]
type = investigation
explanation = none
how_to_implement = Import playbook into phantom
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - GCP Kubernetes activity by src ip - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the GCP App for Splunk (version 2.0.0 or later), then configure stackdriver and set a Pub/Sub subscription to be imported to Splunk. You must also install Cloud Infrastructure data model.Customize the macro kubernetes_gcp_scan_fingerprint_attack_detection to filter out FPs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get All AWS Activity From City - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get All AWS Activity From Country - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get All AWS Activity From IP Address - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get All AWS Activity From Region - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Backup Logs For Endpoint - Response Task]
type = investigation
explanation = none
how_to_implement = You must be ingesting your backup logs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Certificate logs for a domain - Response Task]
type = investigation
explanation = none
how_to_implement = You must be ingesting your certificates or SSL logs from your network traffic into your Certificates datamodel. Please note the wildcard(*) before domain in the search syntax, we use to match for all domain and subdomain combinations
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get DNS Server History for a host - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search, you must be ingesting your DNS traffic
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get DNS traffic ratio - Response Task]
type = investigation
explanation = none
how_to_implement = You must be ingesting your network traffic
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get EC2 Instance Details by instanceId - Response Task]
type = investigation
explanation = none
how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get EC2 Launch Details - Response Task]
type = investigation
explanation = none
how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Email Info - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must be ingesting your email logs or capturing unencrypted network traffic which contains email communications.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Emails From Specific Sender - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get First Occurrence and Last Occurrence of a MAC Address - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search, you must be ingesting the logs from your DHCP server.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get History Of Email Sources - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Logon Rights Modifications For Endpoint - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must be ingesting your Windows event logs
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Logon Rights Modifications For User - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must be ingesting your Windows event logs
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Notable History - Response Task]
type = investigation
explanation = none
how_to_implement = If you are using Enterprise Security you are likely already creating notable events with your correlation rules. No additional configuration is necessary.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Outbound Emails to Hidden Cobra Threat Actors - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Parent Process Info - Response Task]
type = investigation
explanation = none
how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Process File Activity - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must be ingesting endpoint data and populating the Endpoint data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Process Info - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must be ingesting endpoint data and populating the Endpoint data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Process Information For Port Activity - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you must be ingesting endpoint data that associates processes with network events and populate the Endpoint Datamodel
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Process Responsible For The DNS Traffic - Response Task]
type = investigation
explanation = none
how_to_implement = You must be ingesting endpoint data that associates processes with network events into the Endpoint datamodel. This can come from endpoint protection products such as carbon black, or endpoint data sources such as Sysmon.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Sysmon WMI Activity for Host - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search, you must be collecting Sysmon data using Sysmon version 6.1 or greater and have Sysmon configured to generate events for WMI activity. In addition, you must have at least version 6.0.4 of the Sysmon TA installed to properly parse the fields.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Get Web Session Information via session id - Response Task]
type = investigation
explanation = none
how_to_implement = This search leverages data extracted from Stream:HTTP. You must configure the HTTP stream using the Splunk Stream App on your Splunk Stream deployment server.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate AWS User Activities by user field - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate AWS activities via region name - Response Task]
type = investigation
explanation = none
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Failed Logins for Multiple Destinations - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you need to be ingesting authentication logs from your various systems and populating the Authentication data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Network Traffic From src ip - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search, you must be ingesting your web-traffic logs and populating the web data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Okta Activity by IP Address - Response Task]
type = investigation
explanation = none
how_to_implement = You must be ingesting Okta logs
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Okta Activity by app - Response Task]
type = investigation
explanation = none
how_to_implement = You must be ingesting Okta logs
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Pass the Hash Attempts - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you need be ingesting windows security logs. This search uses an input macro named `wineventlog_security`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Security logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Pass the Ticket Attempts - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you need to be ingesting windows security logs. This search uses an input macro named `wineventlog_security`. We strongly recommend that you specify your environment-specific configurations (index, source, sourcetype, etc.) for Windows Security logs. Replace the macro definition with configurations for your Splunk environment. The search also uses a post-filter macro designed to filter out known false positives.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Previous Unseen User - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search you need to be ingesting authentication logs from your various systems and populating the Authentication data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Successful Remote Desktop Authentications - Response Task]
type = investigation
explanation = none
how_to_implement = You must be populating the Authentication data model with security events from your Windows event logs.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Suspicious Strings in HTTP Header - Response Task]
type = investigation
explanation = none
how_to_implement = This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate User Activities In Okta - Response Task]
type = investigation
explanation = none
how_to_implement = You must be ingesting Okta logs
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

[savedsearch://ESCU - Investigate Web POSTs From src - Response Task]
type = investigation
explanation = none
how_to_implement = To successfully implement this search, you must be ingesting your web-traffic logs and populating the web data model.
known_false_positives = not defined
earliest_time_offset = 14400
latest_time_offset = 0

### END RESPONSE TASKS ###

### BASELINES ###
[savedsearch://ESCU - Baseline Of Cloud Infrastructure API Calls Per User]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model for how many API calls are performed by each user. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances created in a small time window.
how_to_implement = You must have Enterprise Security 6.0 or later, if not you will need to verify that the Machine Learning Toolkit (MLTK) version 4.2 or later is installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 90 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline Of Cloud Instances Destroyed]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model for how many instances are destroyed in the environment. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances destroyed in a small time window.
how_to_implement = You must have Enterprise Security 6.0 or later, if not you will need to verify that the Machine Learning Toolkit (MLTK) version 4.2 or later is installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline Of Cloud Instances Launched]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model for how many instances are created in the environment. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of instances created in a small time window.
how_to_implement = You must have Enterprise Security 6.0 or later, if not you will need to verify that the Machine Learning Toolkit (MLTK) version 4.2 or later is installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 90 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline Of Cloud Security Group API Calls Per User]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model for how many API calls for security groups are performed by each user. By default, the search uses the last 90 days of data to build the model and the model is rebuilt weekly.
how_to_implement = You must have Enterprise Security 6.0 or later, if not you will need to verify that the Machine Learning Toolkit (MLTK) version 4.2 or later is installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 90 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of API Calls per User ARN]
type = support
explanation = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of Command Line Length - MLTK]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the command lines observed for each user in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies outliers in the length of the command line.
how_to_implement = You must be ingesting endpoint data and populating the Endpoint data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of DNS Query Length - MLTK]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the length of the DNS queries for each DNS record type observed in the environment. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search, which uses it to identify outliers in the length of the DNS query.
how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of Excessive AWS Instances Launched by User - MLTK]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model for how many RunInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of RunInstances performed by a user in a small time window.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.\
In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of Excessive AWS Instances Terminated by User - MLTK]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model for how many TerminateInstances users do in the environment. By default, the search uses the last 90 days of data to build the model. The model created by this search is then used in the corresponding detection search, which identifies subsequent outliers in the number of TerminateInstances performed by a user in a small time window.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.\
In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. Depending on the number of users in your environment, you may also need to adjust the value for max_inputs in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data.\
More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of Network ACL Activity by ARN]
type = support
explanation = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls that were related to network ACLs made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for network ACLs, edit the macro `network_acl_events`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of S3 Bucket deletion activity by ARN]
type = support
explanation = This search establishes, on a per-hour basis, the average and standard deviation for the number of API calls related to deleting an S3 bucket by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of SMB Traffic - MLTK]
type = support
explanation = This search is used to build a Machine Learning Toolkit (MLTK) model to characterize the number of SMB connections observed each hour for every day of week. By default, the search uses the last 30 days of data to build the model. The model created by this search is then used in the corresponding detection search to identify outliers in the number of SMB connections for that hour and day of the week.
how_to_implement = You must be ingesting network traffic and populating the Network_Traffic data model. In addition, you must have the Machine Learning Toolkit (MLTK) version >= 4.2 installed, along with any required dependencies. To improve your results, you may consider adding "src" to the by clause, which will build the model for each unique source in your enviornment. However, if you have a large number of hosts in your environment, this search may be very resource intensive. In this case, you may need to raise the value of max_inputs and/or max_groups in the MLTK settings for the DensityFunction algorithm, then ensure that the search completes in a reasonable timeframe. By default, the search builds the model using the past 30 days of data. You can modify the search window to build the model over a longer period of time, which may give you better results. You may also want to periodically re-run this search to rebuild the model with the latest data. More information on the algorithm used in the search can be found at `https://docs.splunk.com/Documentation/MLApp/4.2.0/User/Algorithms#DensityFunction`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of Security Group Activity by ARN]
type = support
explanation = This search establishes, on a per-hour basis, the average and the standard deviation for the number of API calls related to security groups made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for security groups, edit the macro `security_group_api_calls`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Baseline of blocked outbound traffic from AWS]
type = support
explanation = This search establishes, on a per-hour basis, the average and the standard deviation of the number of outbound connections blocked in your VPC flow logs by each source IP address (IP address of your EC2 instances). Also recorded is the number of data points for each source IP. This table outputs to a lookup file to allow the detection search to operate quickly.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your `VPC flow logs.`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Count of Unique IPs Connecting to Ports]
type = support
explanation = The search counts the number of times a connection was observed to each destination port, and the number of unique source IPs connecting to them.
how_to_implement = To successfully implement this search, you must be ingesting network traffic, and populating the Network_Traffic data model.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Count of assets by category]
type = support
explanation = This search shows you every asset category you have and the assets that belong to those categories.
how_to_implement = To successfully implement this search you must first leverage the Assets and Identity framework in Enterprise Security to populate your assets_by_str.csv file which should then be mapped to the Identity_Management data model. The Identity_Management data model will contain a list of known authorized company assets. Ensure that all inventoried systems are constantly vetted and updated.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Create a list of approved AWS service accounts]
type = support
explanation = This search looks for successful API activity in CloudTrail within the last 30 days, filters out known users from the identity table, and outputs values of users into `aws_service_accounts.csv` lookup file.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the service account entires in `aws_service_accounts.csv`, which is a lookup file created as a result of running this support search. Please remove the entries of service accounts that are not legitimate.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - DNSTwist Domain Names]
type = support
explanation = This search creates permutations of your existing domains, removes the valid domain names and stores them in a specified lookup file so they can be checked for in the associated detection searches.
how_to_implement = To successfully implement this search you need to update the file called domains.csv in the DA-ESS-SOC/lookup directory. Or `cim_corporate_email_domains.csv` and `cim_corporate_web_domains.csv` from **Splunk\_SA\_CIM**.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Discover DNS records]
type = support
explanation = The search takes corporate and common cloud provider domains configured under `cim_corporate_email_domains.csv`, `cim_corporate_web_domains.csv`, and `cloud_domains.csv` finds their responses across the last 30 days from data in the `Network_Resolution ` datamodel, then stores the output under the `discovered_dns_records.csv` lookup
how_to_implement = To successfully implement this search, you must be ingesting DNS logs, and populating the Network_Resolution data model. Also make sure that the cim_corporate_web_domains and cim_corporate_email_domains lookups are populated with the domains owned by your corporation
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Identify Systems Creating Remote Desktop Traffic]
type = support
explanation = This search counts the numbers of times the system has generated remote desktop traffic.
how_to_implement = To successfully implement this search, you must ingest network traffic and populate the Network_Traffic data model.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Identify Systems Receiving Remote Desktop Traffic]
type = support
explanation = This search counts the numbers of times the system has created remote desktop traffic
how_to_implement = To successfully implement this search you must ingest network traffic and populate the Network_Traffic data model. If a system receives a lot of remote desktop traffic, you can apply the category common_rdp_destination to it.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Identify Systems Using Remote Desktop]
type = support
explanation = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system.
how_to_implement = To successfully implement this search you must be ingesting endpoint data that records process activity.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Monitor Successful Backups]
type = support
explanation = This search is intended to give you a feel for how often successful backups are conducted in your environment. Fluctuations in these numbers will allow you to determine when you should investigate.
how_to_implement = To successfully implement this search you must be ingesting your backup logs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Monitor Unsuccessful Backups]
type = support
explanation = This search is intended to give you a feel for how often backup failures happen in your environments.  Fluctuations in these numbers will allow you to determine when you should investigate.
how_to_implement = To successfully implement this search you must be ingesting your backup logs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen AWS Cross Account Activity]
type = support
explanation = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen AWS Cross Account Activity - Initial]
type = support
explanation = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later)and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen AWS Cross Account Activity - Update]
type = support
explanation = This search looks for **AssumeRole** events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen AWS Provisioning Activity Sources]
type = support
explanation = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen AWS Regions]
type = support
explanation = This search looks for CloudTrail events where an AWS instance is started and creates a baseline of most recent time (latest) and the first time (earliest) we've seen this region in our dataset grouped by the value awsRegion for the last 30 days
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud API Calls Per User Role - Initial]
type = support
explanation = This search builds a table of the first and last times seen for every user role and command combination. This is broadly defined as any event that runs or creates something. This table is then cached.
how_to_implement = You must be ingesting Cloud infrastructure logs from your cloud provider.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud API Calls Per User Role - Update]
type = support
explanation = This search updates the table of the first and last times seen for every user role and command combination.
how_to_implement = You must be ingesting Cloud infrastructure logs from your cloud provider.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Compute Creations By User - Initial]
type = support
explanation = This search builds a table of previously seen users that have launched a cloud compute instance.
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the proper TAs installed.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Compute Creations By User - Update]
type = support
explanation = This search builds a table of previously seen users that have launched a cloud compute instance.
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the proper TAs installed.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Compute Images - Initial]
type = support
explanation = This search builds a table of previously seen images used to launch cloud compute instances
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the latest Change Datamodel accelerated
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Compute Images - Update]
type = support
explanation = This search builds a table of previously seen images used to launch cloud compute instances
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Compute Instance Types - Initial]
type = support
explanation = This search builds a table of previously seen cloud compute instance types
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Compute Instance Types - Update]
type = support
explanation = This search builds a table of previously seen cloud compute instance types
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Instance Modifications By User - Initial]
type = support
explanation = This search builds a table of previously seen users that have modified a cloud instance.
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the latest Change Datamodel accelerated.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Instance Modifications By User - Update]
type = support
explanation = This search updates a table of previously seen Cloud Instance modifications that have been made by a user
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Provisioning Activity Sources - Initial]
type = support
explanation = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something. This table is then cached.
how_to_implement = You must be ingesting Cloud infrastructure logs from your cloud provider.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Provisioning Activity Sources - Update]
type = support
explanation = This returns the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity within the last day. Cloud provisioning is broadly defined as any event that runs or creates something.  It then updates this information with historical data and filters out locations that have not been seen within the specified time window. This updated table is then cached.
how_to_implement = You must be ingesting Cloud infrastructure logs from your cloud provider.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Regions - Initial]
type = support
explanation = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Cloud Regions - Update]
type = support
explanation = This search looks for cloud compute events where a compute instance is started and creates a baseline of most recent time, `lastTime` and the first time `firstTime` we've seen this region in our dataset grouped by the region for the last 30 days
how_to_implement = You must be ingesting the approrpiate cloud infrastructure logs and have the Security Research cloud data model installed.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen EC2 AMIs]
type = support
explanation = This search builds a table of previously seen AMIs used to launch EC2 instances
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen EC2 Instance Types]
type = support
explanation = This search builds a table of previously seen EC2 instance types
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen EC2 Launches By User]
type = support
explanation = This search builds a table of previously seen ARNs that have launched a EC2 instance.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen EC2 Modifications By User]
type = support
explanation = This search builds a table of previously seen ARNs that have launched a EC2 instance.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2_modification_api_calls`.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Running Windows Services - Initial]
type = support
explanation = This collects the services that have been started across your entire enterprise.
how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs for it to execute successfully. Please ensure that the Splunk Add-on for Microsoft Windows is version 8.0.0 or above.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Running Windows Services - Update]
type = support
explanation = This search returns the first and last time a Windows service was seen across your enterprise within the last hour. It then updates this information with historical data and filters out Windows services pairs that have not been seen within the specified time window. This updated table is then cached.
how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs for it to execute successfully. Please ensure that the Splunk Add-on for Microsoft Windows is version 8.0.0 or above.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Users In CloudTrail - Update]
type = support
explanation = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by user, within the last hour.
how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_users_console_logins`, which is a lookup file created by this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Users in CloudTrail - Initial]
type = support
explanation = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by username, within the last 30 days.
how_to_implement = You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Validate the user name entries in `previously_seen_users_console_logins`, which is a lookup file created by this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Zoom Child Processes - Initial]
type = support
explanation = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS). This table is then cached.
how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously Seen Zoom Child Processes - Update]
type = support
explanation = This search returns the first and last time a process was seen per endpoint with a parent process of zoom.exe (Windows) or zoom.us (macOS) within the last hour. It then updates this information with historical data and filters out proces_name and endpoint pairs that have not been seen within the specified time window. This updated table is outputed to disk.
how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints, to populate the Endpoint data model in the Processes node.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously seen API call per user roles in CloudTrail]
type = support
explanation = This search looks for successful API calls made by different user roles, then creates a baseline of the earliest and latest times we have encountered this user role. It also returns the name of the API call in our dataset--grouped by user role and name of the API call--that occurred within the last 30 days. In this support search, we are only looking for events where the user identity is Assumed Role.
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user role entries in `previously_seen_api_calls_from_user_roles.csv`, which is a lookup file created as a result of running this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously seen S3 bucket access by remote IP]
type = support
explanation = This search looks for successful access to S3 buckets from remote IP addresses, then creates a baseline of the earliest and latest times we have encountered this remote IP within the last 30 days. In this support search, we are only looking for S3 access events where the HTTP response code from AWS is "200"
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access-logs inputs. You must validate the remote IP and bucket name entries in `previously_seen_S3_access_from_remote_ip.csv`, which is a lookup file created as a result of running this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously seen command line arguments]
type = support
explanation = This search looks for command-line arguments where `cmd.exe /c` is used to execute a program, then creates a baseline of the earliest and latest times we have encountered this command-line argument in our dataset within the last 30 days.
how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Previously seen users in CloudTrail]
type = support
explanation = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last 30 days. NOTE - This baseline search is deprecated and has been updated to use the Authentication Datamodel
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins_cloudtrail`, which is a lookup file created as a result of running this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Systems Ready for Spectre-Meltdown Windows Patch]
type = support
explanation = Some AV applications can cause the Spectre/Meltdown patch for Windows not to install successfully. This registry key is supposed to be created by the AV engine when it has been patched to be able to handle the Windows patch. If this key has been written, the system can then be patched for Spectre and Meltdown.
how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Update previously seen users in CloudTrail]
type = support
explanation = This search looks for CloudTrail events where a user logs into the console, then updates the baseline of the latest and earliest times, City, Region, and Country we have encountered this user in our dataset, grouped by ARN, within the last hour. NOTE - This baseline search is deprecated and has been updated to use the Authentication Datamodel
how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins_cloudtrail`, which is a lookup file created as a result of running this support search.
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Windows Updates Install Failures]
type = support
explanation = This search is intended to give you a feel for how often Windows updates fail to install in your environment. Fluctuations in these numbers will allow you to determine when you should be concerned.
how_to_implement = You must be ingesting your Windows Update Logs
known_false_positives = not defined
providing_technologies = none

[savedsearch://ESCU - Windows Updates Install Successes]
type = support
explanation = This search is intended to give you a feel for how often successful Windows updates are applied in your environments. Fluctuations in these numbers will allow you to determine when you should be concerned.
how_to_implement = You must be ingesting your Windows Update Logs
known_false_positives = not defined
providing_technologies = none

### END ESCU BASELINES ###